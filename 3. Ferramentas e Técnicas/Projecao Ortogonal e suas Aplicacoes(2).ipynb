{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='orth-proj'></a>\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeção Ortogonal e suas Aplicações \n",
    "\n",
    "\n",
    "<a id='index-0'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "- [Projeção Ortogonal e suas Aplicações](#Projeção-Ortogonal-e-suas-Aplicações)  \n",
    "  - [Resumo](#Resumo)  \n",
    "  - [Definições Chave](#Definições-Chave)  \n",
    "  - [O Teorema da Projeção Ortogonal](#O-Teorema-da-Projeção-Ortogonal)  \n",
    "  - [Base Ortonormal](#Base-Ortonormal)  \n",
    "  - [Projeção usando Álgebra Matricial](#Projeção-usando-Álgebra-Matricial)  \n",
    "  - [Regressão dos Mínimos Quadrados](#Regressão-dos-Mínimos-Quadrados)  \n",
    "  - [Ortogonalização e Decomposição](#Ortogonalização-e-Decomposição)  \n",
    "  - [Exercícios](#Exercícios)  \n",
    "  - [Soluções](#Soluções)  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Devidamente traduzido, revisado e adaptado pelos bolsistas CNPq Pedro Luiz H. Furtado e Jonas Aragão M. Corpes, sob a supervisão do Prof. Christiano Penna, pesquisador do CAEN/UFC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "A projeção ortogonal é uma pedra angular dos métodos de espaço vetorial, com muitas aplicações diversas.\n",
    "\n",
    "Isso inclui, entre outros,\n",
    "\n",
    "- Projeção de mínimos quadrados, também conhecida como regressão linear  \n",
    "- Expectativas condicionais para distribuições normais multivariadas (Gaussianas)  \n",
    "- Ortogonalização de Gram–Schmidt  \n",
    "- Decomposição QR  \n",
    "- Polinômios Ortogonais  \n",
    "- etc  \n",
    "\n",
    "\n",
    "Nesta aula, vamos focar em :\n",
    "\n",
    "- idéias chaves  \n",
    "- regressão dos mínimos quadrados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura Adicional\n",
    "\n",
    "Para conceitos básicos e fundamentais, consulte nossa palestra [sobre álgebra linear](https://julia.quantecon.org/tools_and_techniques/linear_algebra.html)\n",
    "\n",
    "Para mais provas e maiores detalhes teóricos, veja [A Primer in Econometric Theory](http://www.johnstachurski.net/emet.html)\n",
    "\n",
    "Para um completo conjunto de provas em uma configuração geral, consulte, por exemplo, [[Rom05]](https://julia.quantecon.org/zreferences.html#roman2005)\n",
    "\n",
    "Para um tratamento avançado da projeção no contexto da previsão de mínimos quadrados, consulte [o capítulo deste livro](http://www.tomsargent.com/books/TOMchpt.2.pdf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definições Chave\n",
    "\n",
    "Suponha que  $ x, z \\in \\mathbb{R}^n $\n",
    "\n",
    "Defina $ \\langle x,  z\\rangle = \\sum_i x_i z_i $\n",
    "\n",
    "lembre-se $ \\|x \\|^2 = \\langle x, x \\rangle $\n",
    "\n",
    "A **lei dos cossenos** afirma que $ \\langle x, z \\rangle = \\| x \\| \\| z \\| \\cos(\\theta) $ onde $ \\theta $ é o ângulo entre os vetores $ x $ e $ z $\n",
    "\n",
    "Quando $ \\langle x,  z\\rangle = 0 $, então $ \\cos(\\theta) = 0 $ e  $ x $ e $ z $ é dito ser **ortogonal** e escrevemos $ x \\perp z $\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_def1.png\" style=\"width:50%;\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um subespaço linear  $ S \\subset \\mathbb{R}^n $, chamamos $ x \\in \\mathbb{R}^n $ **ortogonal para** $ S $ se $ x \\perp z $ para todos $ z \\in S $, e escrevemos $ x \\perp S $\n",
    "\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_def2.png\" style=\"width:50%;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **complemento ortogonal** de um subespaço linear $ S \\subset \\mathbb{R}^n $ é o conjunto $ S^{\\perp} := \\{x \\in \\mathbb{R}^n \\,:\\, x \\perp S\\} $\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_def3.png\" style=\"width:50%;\">\n",
    "\n",
    "  \n",
    "$ S^\\perp $ é um subespaço linear de  $ \\mathbb{R}^n $\n",
    "\n",
    "- Para ver isso, deixe $ x, y \\in S^{\\perp} $ e $ \\alpha, \\beta \\in \\mathbb{R} $  \n",
    "- Observe que se $ z \\in S $, entãp  \n",
    "\n",
    "\n",
    "$$\n",
    "\\langle \\alpha x + \\beta y, z \\rangle\n",
    "= \\alpha \\langle x, z \\rangle + \\beta \\langle y, z \\rangle\n",
    " = \\alpha \\times 0  + \\beta \\times 0 = 0\n",
    "$$\n",
    "\n",
    "- Consequentemente $ \\alpha x + \\beta y \\in S^{\\perp} $, como era para ser mostrado \n",
    "\n",
    "\n",
    "Um conjunto de vetores $ \\{x_1, \\ldots, x_k\\} \\subset \\mathbb{R}^n $ é chamado de um **conjunto ortogonal** se $ x_i \\perp x_j $ sempre que $ i \\not= j $\n",
    "\n",
    "Se $ \\{x_1, \\ldots, x_k\\} $ é um conjunto ortogonal, então **a lei Pitágoras** afirma que\n",
    "\n",
    "$$\n",
    "\\| x_1 + \\cdots + x_k \\|^2\n",
    "= \\| x_1 \\|^2 + \\cdots + \\| x_k \\|^2\n",
    "$$\n",
    "\n",
    "Por exemplo, quando $ k=2 $, $ x_1 \\perp x_2 $ implica\n",
    "\n",
    "$$\n",
    "\\| x_1 + x_2 \\|^2\n",
    " = \\langle x_1 + x_2, x_1 + x_2 \\rangle\n",
    " = \\langle x_1, x_1 \\rangle + 2 \\langle  x_2, x_1 \\rangle + \\langle x_2, x_2 \\rangle\n",
    " = \\| x_1 \\|^2 + \\| x_2 \\|^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independência Linear vs Ortogonalidade\n",
    "\n",
    "Se $ X \\subset \\mathbb{R}^n $ é um conjunto ortogonal e $ 0 \\notin X $, então $ X $ é literalmente independente \n",
    "\n",
    "Provar isso é um bom exercício\n",
    "\n",
    "Embora o inverso não seja verdadeiro, um tipo de inverso parcial se mantém, como veremos [abaixo](#gram-schmidt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Teorema da Projeção Ortogonal\n",
    "\n",
    "Que vetor dentro de um subespaço linear de $ \\mathbb{R}^n $  melhor aproxima um dado vetor em $ \\mathbb{R}^n $?\n",
    "\n",
    "O próximo teorema fornece respostas para esta pergunta\n",
    "\n",
    "**Teorema** (OPT) Dado $ y \\in \\mathbb{R}^n $ e subespaço  $ S \\subset \\mathbb{R}^n $,\n",
    "existe uma única solução para minimizar o problema\n",
    "\n",
    "$$\n",
    "\\hat y := \\mathop{\\mathrm{arg\\,min}}_{z \\in S} \\|y - z\\|\n",
    "$$\n",
    "\n",
    "O minimizador $ \\hat y $ é o único vetor em $ \\mathbb{R}^n $ que satisfaz\n",
    "\n",
    "- $ \\hat y \\in S $  \n",
    "- $ y - \\hat y \\perp S $  \n",
    "\n",
    "\n",
    "O vetor $ \\hat y $ é chamado de **projeção ortogonal** de $ y $ para $ S $\n",
    "\n",
    "A próxima figura fornece alguma intuição\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_thm1.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova de Suficiência\n",
    "\n",
    "Omitiremos a prova completa.\n",
    "\n",
    "Mas provaremos a suficiência das condições afirmadas.\n",
    "\n",
    "Para este fim, faça $ y \\in \\mathbb{R}^n $ e deixe $ S $ ser um subespaço linear de $ \\mathbb{R}^n $\n",
    "\n",
    "Deixe $ \\hat y $ ser um vetor em $ \\mathbb{R}^n $ de tal modo que $ \\hat y \\in S $ e $ y - \\hat y \\perp S $\n",
    "\n",
    "Faça $ z $ ser qualquer outro ponto em $ S $ e use o fato que $ S $ é um subespaço linear para deduzir\n",
    "\n",
    "$$\n",
    "\\| y - z \\|^2\n",
    "= \\| (y - \\hat y) + (\\hat y - z) \\|^2\n",
    "= \\| y - \\hat y \\|^2  + \\| \\hat y - z  \\|^2\n",
    "$$\n",
    "\n",
    "Consequentemente $ \\| y - z \\| \\geq \\| y - \\hat y \\| $, que completa a prova"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeção Ortogonal como Mapeamento\n",
    "\n",
    "Para um espaço linear $ Y $ e um subespaço linear fixo $ S $, temos uma funcional relação\n",
    "\n",
    "$$\n",
    "y \\in Y\\; \\mapsto \\text{ sua projeção ortogonal} \\hat y \\in S\n",
    "$$\n",
    "\n",
    "A partir de OPT, isto é um mapeamento bem definido  ou *operador* de $ \\mathbb{R}^n $ para $ \\mathbb{R}^n $\n",
    "\n",
    "No que segue nos denotamos este operador pela matriz $ P $\n",
    "\n",
    "- $ P y $ representa a projeção $ \\hat y $  \n",
    "- Isto às vezes é apresentado é expressado como $ \\hat E_S y = P y $, onde $ \\hat E $ denota um **operador de expectativas de senso amplo** e o subscrito $ S $ indica que estamos projetando $ y $ para o subespaço linear $ S $  \n",
    "\n",
    "\n",
    "O operador $ P $ é chamado de **mapeamento de projeção ortogonal para** $ S $\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_thm2.png\" style=\"width:50%;\">\n",
    "\n",
    "  \n",
    "É imediato do OPT que para qualquer $ y \\in \\mathbb{R}^n $\n",
    "\n",
    "1. $ P y \\in S $ e  \n",
    "1. $ y - P y \\perp S $  \n",
    "\n",
    "\n",
    "Disso podemos deduzir as propriedades utéis adicionais, tais como\n",
    "\n",
    "1. $ \\| y \\|^2 = \\| P y \\|^2 + \\| y - P y \\|^2 $ e  \n",
    "1. $ \\| P y \\| \\leq \\| y \\| $  \n",
    "\n",
    "\n",
    "Por exemplo, para provar 1, observe que $ y  = P y  + y - P y $ e aplique a lei de Pitágoras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complemeto Ortogonal\n",
    "\n",
    "Faça $ S \\subset \\mathbb{R}^n $.\n",
    "\n",
    "O **complemento ortogonal** de $ S $ é o subespaço linear $ S^{\\perp} $ que satisfaz\n",
    "$ x_1 \\perp x_2 $ para todo $ x_1 \\in S $ e $ x_2 \\in S^{\\perp} $\n",
    "\n",
    "Deixe $ Y $ ser um espaço linear com um subespaço linear $ S $ e seu complemento ortogonal $ S^{\\perp} $\n",
    "\n",
    "Escrevemos\n",
    "\n",
    "$$\n",
    "Y = S \\oplus S^{\\perp}\n",
    "$$\n",
    "\n",
    "para indicar que para todo $ y \\in Y $ existe único $ x_1 \\in S $ e um único $ x_2 \\in S^{\\perp} $\n",
    "de tal modo que $ y = x_1 + x_2 $.\n",
    "\n",
    "Além disso, $ x_1 = \\hat E_S y $ e $ x_2 = y - \\hat E_S y $\n",
    "\n",
    "Isso equivale a outra versão do OPT:\n",
    "\n",
    "**Teorema**.  Se $ S $ é um subespaço linear de $ \\mathbb{R}^n $, $ \\hat E_S y = P y $ e $ \\hat E_{S^{\\perp}} y = M y $, então\n",
    "\n",
    "$$\n",
    "P y \\perp M y\n",
    " \\quad \\text{e} \\quad\n",
    "y = P y + M y\n",
    " \\quad \\text{para todo } \\, y \\in \\mathbb{R}^n\n",
    "$$\n",
    "\n",
    "A próxima figura ilustra\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/tools_and_techniques/_static/figures/orth_proj_thm3.png\" style=\"width:50%;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Ortonormal\n",
    "\n",
    "Um conjunto de vetores ortorgonal $ O \\subset \\mathbb{R}^n $ é chamado de **conjunto ortonormal** se $ \\| u \\| = 1 $ para todo $ u \\in O $\n",
    "\n",
    "Deixe $ S $ ser um subespaço linear de $ \\mathbb{R}^n $ e deixe $ O \\subset S $\n",
    "\n",
    "Se $ O $ é ortonormal e $ \\mathop{\\mathrm{span}} O = S $, então $ O $ é chamada de uma **base ortonormal** de $ S $\n",
    "\n",
    "$ O $ é necessariamente uma base de  $ S $ (sendo independente pela ortogonalidade e pelo fato de nenhum elemento ser o vetor zero)\n",
    "\n",
    "Um exemplo de um conjunto ortonormal é a base canônina $ \\{e_1, \\ldots, e_n\\} $\n",
    "que forma uma base ortonormal de $ \\mathbb{R}^n $, onde $ e_i $ é o  vetor unitário $ i $\n",
    "\n",
    "Se $ \\{u_1, \\ldots, u_k\\} $ é uma base ortonormal de um subespaço linear $ S $, então\n",
    "\n",
    "$$\n",
    "x = \\sum_{i=1}^k \\langle x, u_i \\rangle u_i\n",
    "\\quad \\text{para todo} \\quad\n",
    "x \\in S\n",
    "$$\n",
    "\n",
    "Para ver isso, observe que desde $ x \\in \\mathop{\\mathrm{período}}\\{u_1, \\ldots, u_k\\} $, podemos encontrar \n",
    "escalares $ \\alpha_1, \\ldots, \\alpha_k $ that verify\n",
    "\n",
    "\n",
    "<a id='equation-pob'></a>\n",
    "$$\n",
    "x = \\sum_{j=1}^k \\alpha_j u_j \\tag{1}\n",
    "$$\n",
    "\n",
    "Tomando o produto interno com relação a $ u_i $ dado\n",
    "\n",
    "$$\n",
    "\\langle x, u_i \\rangle\n",
    "= \\sum_{j=1}^k \\alpha_j \\langle u_j, u_i \\rangle\n",
    "= \\alpha_i\n",
    "$$\n",
    "\n",
    "Combinando este resultado com [(1)](#equation-pob) verifica a afirmação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projeção para uma Base Ortonormal\n",
    "\n",
    "Quando o subespaço no qual está projetando é ortonormal, o cálculo da projeção simplifica:\n",
    "\n",
    "**Teorema** Se $ \\{u_1, \\ldots, u_k\\} $ é uma base ortonormal para $ S $, então\n",
    "\n",
    "\n",
    "<a id='equation-exp-for-op'></a>\n",
    "$$\n",
    "P y = \\sum_{i=1}^k \\langle y, u_i \\rangle u_i,\n",
    "\\quad\n",
    "\\forall \\; y \\in \\mathbb{R}^n \\tag{2}\n",
    "$$\n",
    "\n",
    "Prova: Determine $ y \\in \\mathbb{R}^n $ deixe $ P y $ ser definido como em [(2)](#equation-exp-for-op)\n",
    "\n",
    "Claramente, $ P y \\in S $\n",
    "\n",
    "Afirmamos que $ y - P y \\perp S $ também detem\n",
    "\n",
    "Basta mostrar que $ y - P y \\perp $ qualquer vetor base $ u_i $ (por quê?)\n",
    "\n",
    "Isso é verdade porque\n",
    "\n",
    "$$\n",
    "\\left\\langle y - \\sum_{i=1}^k \\langle y, u_i \\rangle u_i, u_j \\right\\rangle\n",
    "= \\langle y, u_j \\rangle  - \\sum_{i=1}^k \\langle y, u_i \\rangle\n",
    "\\langle u_i, u_j  \\rangle = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeção usando Álgebra Matricial\n",
    "\n",
    "Deixer $ S $ ser um subespaço linear $ \\mathbb{R}^n $ e faça $ y \\in \\mathbb{R}^n $.\n",
    "\n",
    "Nós queremos computar a matriz $ P $ que verifica: \n",
    "\n",
    "$$\n",
    "\\hat E_S y = P y\n",
    "$$\n",
    "\n",
    "Evidencialmente $ Py $ é uma função linear de $ y \\in \\mathbb{R}^n $ para $ P y \\in \\mathbb{R}^n $\n",
    "\n",
    "Esta referência é usual [https://en.wikipedia.org/wiki/Linear_map#Matrices](https://en.wikipedia.org/wiki/Linear_map#Matrices)\n",
    "\n",
    "**Teorema.** Faça as colunas $ n \\times k $ da matriz $ X $ formar uma base de $ S $.  então\n",
    "\n",
    "$$\n",
    "P = X (X'X)^{-1} X'\n",
    "$$\n",
    "\n",
    "Prova: Dado arbitrário $ y \\in \\mathbb{R}^n $ e $ P = X (X'X)^{-1} X' $, nossa afirmação é que\n",
    "\n",
    "1. $ P y \\in S $, e  \n",
    "1. $ y - P y \\perp S $  \n",
    "\n",
    "\n",
    "Afirmação 1 é verdade porque\n",
    "\n",
    "$$\n",
    "P y = X (X' X)^{-1} X' y = X a\n",
    "\\quad \\text{quando} \\quad\n",
    "a := (X' X)^{-1} X' y\n",
    "$$\n",
    "\n",
    "Uma expressão da forma $ X a $ é precisamente uma combinação linear de colunas de $ X $, e consequentemente um elemento de $ S $\n",
    "\n",
    "Afirmação 2 é equivalente a declaração\n",
    "\n",
    "$$\n",
    "y - X (X' X)^{-1} X' y \\, \\perp\\,  X b\n",
    "\\quad \\text{para todo} \\quad\n",
    "b \\in \\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "Isto é verdade: Se $ b \\in \\mathbb{R}^K $, então\n",
    "\n",
    "$$\n",
    "(X b)' [y - X (X' X)^{-1} X'\n",
    "y]\n",
    "= b' [X' y - X' y]\n",
    "= 0\n",
    "$$\n",
    "\n",
    "A prova agora está completa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Começando com $ X $\n",
    "\n",
    "Em aplicações é comum começar com $ n \\times k $ matriz $ X $  com colunas linearmente independentes e faça\n",
    "\n",
    "$$\n",
    "S := \\mathop{\\mathrm{período}} X := \\mathop{\\mathrm{período}} \\{\\mathop{\\mathrm{col}}_1 X, \\ldots, \\mathop{\\mathrm{col}}_k X \\}\n",
    "$$\n",
    "\n",
    "Então as colunas de $ X $ formam uma base de $ S $\n",
    "\n",
    "A partir do teorema anterior, $ P = X (X' X)^{-1} X' y $ projeta $ y $ para $ S $\n",
    "\n",
    "Nesse contexto, $ P $ é geralmente chamado de **matriz de projeção**\n",
    "\n",
    "- A Matriz $ M = I - P $ satisfaz $ M y = \\hat E_{S^{\\perp}} y $ e às vezes é chamada de **matriz aniquiladora**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O caso Ortonormal\n",
    "\n",
    "Suponha que $ U $ é $ n \\times k $ com colunas ortonormais\n",
    "\n",
    "Faça $ u_i := \\mathop{\\mathrm{coluna}} U_i $ para cada $ i $, faça $ S := \\mathop{\\mathrm{período}} U $ e faça $ y \\in \\mathbb{R}^n $\n",
    "\n",
    "Sabemos que a projeção de $ y $ para $ S $ is\n",
    "\n",
    "$$\n",
    "P y = U (U' U)^{-1} U' y\n",
    "$$\n",
    "\n",
    "Desde $ U $ tenha colunas ortonormais, temos  $ U' U = I $\n",
    "\n",
    "Logo\n",
    "\n",
    "$$\n",
    "P y\n",
    "= U U' y\n",
    "= \\sum_{i=1}^k \\langle u_i, y \\rangle u_i\n",
    "$$\n",
    "\n",
    "Recuperamos nosso resultado anterior sobre a projeção para uma extensão ortonormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação: Sistemas de Equações Sobredeterminadas\n",
    "\n",
    "Permita $ y \\in \\mathbb{R}^n $ e deixe $ X $ ser $ n \\times k $ com colunas linearmente independentes\n",
    "\n",
    "Dado $ X $ e $ y $, procuramos $ b \\in \\mathbb{R}^k $ que satisfaça o sistema de equações linear $ X b = y $\n",
    "\n",
    "Se $ n > k $ (mais equações que conhecidas), então $ b $ é dito ser **sobredeterminada**\n",
    "\n",
    "Intuitivamente, nós não devemos ser capaz de encontrar um $ b $ que satisfaça todas as $ n $ equações\n",
    "\n",
    "A melhor aproximação aqui é por\n",
    "\n",
    "- Aceitar que uma solução exata não deve existir\n",
    "- Procurar em vez de uma solução aproximada \n",
    "\n",
    "\n",
    "Pela solução aproximada, queremos dizer um $ b \\in \\mathbb{R}^k $ de modo que $ X b $ é tão próximo a $ y $ quanto possivel\n",
    "\n",
    "O próximo teorema mostra que a solução é bem definida e única\n",
    "\n",
    "A prova usa o OPT\n",
    "\n",
    "**Teorema** O único minimizador  $ \\| y - X b \\| $ sobre $ b \\in \\mathbb{R}^K $ é\n",
    "\n",
    "$$\n",
    "\\hat \\beta := (X' X)^{-1} X' y\n",
    "$$\n",
    "\n",
    "Prova:  Observe que\n",
    "\n",
    "$$\n",
    "X \\hat \\beta = X (X' X)^{-1} X' y =\n",
    "P y\n",
    "$$\n",
    "\n",
    "Desde que $ P y $ seja uma projeção ortogonal para $ \\mathop{\\mathrm{período}}(X) $ temos\n",
    "\n",
    "$$\n",
    "\\| y - P y \\|\n",
    "\\leq \\| y - z \\| \\text{ para qualquer } z \\in \\mathop{\\mathrm{período}}(X)\n",
    "$$\n",
    "\n",
    "Porque $ Xb \\in \\mathop{\\mathrm{período}}(X) $\n",
    "\n",
    "$$\n",
    "\\| y - X \\hat \\beta \\|\n",
    "\\leq \\| y - X b \\| \\text{ para qualquer } b \\in \\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "Isto é o que procuramos mostrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão dos Mínimos Quadrados\n",
    "\n",
    "Vamos aplicar a teoria da projeção ortogonal para regressões dos mínimos quadrados.\n",
    "\n",
    "Essa aproximação fornece uma compreensão sobre muitas propriedades geométricas da regressão linear.\n",
    "\n",
    "Nós trataremos apenas de alguns exemplos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medidas de Risco ao Quadrado\n",
    "\n",
    "Dado pares $ (x, y) \\in \\mathbb{R}^K \\times \\mathbb{R} $, considere escolher $ f \\colon \\mathbb{R}^K \\to \\mathbb{R} $ para minimizar o **risco**\n",
    "\n",
    "$$\n",
    "R(f) := \\mathbb{E}\\, [(y - f(x))^2]\n",
    "$$\n",
    "\n",
    "Se probabilidades e portanto $ \\mathbb{E}\\, $ são desconhecidos, não podemos resolver esse problema diretamente.\n",
    "\n",
    "No entanto, se uma amostra estiver disponível, podemos estimar o risco com o **risco empírico**:\n",
    "\n",
    "$$\n",
    "\\min_{f \\in \\mathcal{F}} \\frac{1}{N} \\sum_{n=1}^N (y_n - f(x_n))^2\n",
    "$$\n",
    "\n",
    "Minimizar essa expressão é chamar de **minimização do risco empírico**\n",
    "\n",
    "O conjunto $ \\mathcal{F} $ às vezes é chamado de hipótese de espaço.\n",
    "\n",
    "A teoria do aprendizado estatístico nos conta que para previnir o sobreajuste devemos tomar o conjunto $ \\mathcal{F} $ para ser relativamente simples.\n",
    "\n",
    "Se deixarmos $ \\mathcal{F} $ ser a classe das funções lineares $ 1/N $, o problema é:\n",
    "\n",
    "$$\n",
    "\\min_{b \\in \\mathbb{R}^K} \\;\n",
    "\\sum_{n=1}^N (y_n - b' x_n)^2\n",
    "$$\n",
    "\n",
    "Esta é uma pequena amostra do **problema de mínimos quadrados linear**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solução\n",
    "\n",
    "Defina as matrizes\n",
    "\n",
    "$$\n",
    "y :=\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    y_1 \\\\\n",
    "    y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    y_N\n",
    "\\end{array}\n",
    "\\right),\n",
    "\\quad\n",
    "x_n :=\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    x_{n1} \\\\\n",
    "    x_{n2} \\\\\n",
    "    \\vdots \\\\\n",
    "    x_{nK}\n",
    "\\end{array}\n",
    "\\right)\n",
    "= \\text{ \\$ n\\$-ésimo obs em todos os regressores}\n",
    "$$\n",
    "\n",
    "e\n",
    "\n",
    "$$\n",
    "X :=\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    x_1'  \\\\\n",
    "    x_2'  \\\\\n",
    "    \\vdots     \\\\\n",
    "    x_N'\n",
    "\\end{array}\n",
    "\\right)\n",
    ":=:\n",
    "\\left(\n",
    "\\begin{array}{cccc}\n",
    "    x_{11} & x_{12} & \\cdots & x_{1K} \\\\\n",
    "    x_{21} & x_{22} & \\cdots & x_{2K} \\\\\n",
    "    \\vdots & \\vdots &  & \\vdots \\\\\n",
    "    x_{N1} & x_{N2} & \\cdots & x_{NK}\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "Nós assumimos ao longo que $ N > K $ e $ X $ é uma coluna posto completo\n",
    "\n",
    "Se você trabalhar com a álgebra, poderá verificar se $ \\| y - X b \\|^2 = \\sum_{n=1}^N (y_n - b' x_n)^2 $\n",
    "\n",
    "Como as transformações monótonas não afetam os minimizadores, temos\n",
    "\n",
    "$$\n",
    "\\mathop{\\mathrm{arg\\,min}}_{b \\in \\mathbb{R}^K} \\sum_{n=1}^N (y_n - b' x_n)^2\n",
    "= \\mathop{\\mathrm{arg\\,min}}_{b \\in \\mathbb{R}^K} \\| y - X b \\|\n",
    "$$\n",
    "\n",
    "Pelos nossos resultados sobre sistemas lineares sobredeterminados de equações, a solução é\n",
    "\n",
    "$$\n",
    "\\hat \\beta := (X' X)^{-1} X' y\n",
    "$$\n",
    "\n",
    "Deixe $ P $ e $ M $ ser a projeção e o aniquilador associado a $ X $:\n",
    "\n",
    "$$\n",
    "P := X (X' X)^{-1} X'\n",
    "\\quad \\text{e} \\quad\n",
    "M := I - P\n",
    "$$\n",
    "\n",
    "O **vetor de valores ajustados** é\n",
    "\n",
    "$$\n",
    "\\hat y := X \\hat \\beta = P y\n",
    "$$\n",
    "\n",
    "O **vetor de resíduos** é\n",
    "\n",
    "$$\n",
    "\\hat u :=  y - \\hat y = y - P y = M y\n",
    "$$\n",
    "\n",
    "Aqui segue mais algumas definições padrões:\n",
    "\n",
    "- A **soma dos quadrados totais** é $ :=  \\| y \\|^2 $  \n",
    "- A **soma dos quadrados dos resíduos** é $ := \\| \\hat u \\|^2 $  \n",
    "- A **soma dos quadrados explicados** é $ := \\| \\hat y \\|^2 $  \n",
    "\n",
    "\n",
    "> TSS = ESS + SSR\n",
    "\n",
    "\n",
    "Nós podemos facilmente provar isso usando OPT\n",
    "\n",
    "A partir do OPT temos $ y =  \\hat y + \\hat u $ e $ \\hat u \\perp \\hat y $\n",
    "\n",
    "A aplicação da lei de Pitágoras completa a prova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ortogonalização e Decomposição\n",
    "\n",
    "Vamos voltar à conexão entre independência linear e ortogonalidade mencionada acima.\n",
    "\n",
    "Um resultado de muito interesse é um famoso algoritmo para a construção de conjuntos ortonormais a partir de conjuntos linearmente independentes.\n",
    "\n",
    "A próxima seção fornece detalhes.\n",
    "\n",
    "\n",
    "<a id='gram-schmidt'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ortogonalização de Gram-Schmidt \n",
    "\n",
    "**Teorema** Para cada conjunto linearmente independete $ \\{x_1, \\ldots, x_k\\} \\subset \\mathbb{R}^n $, existe um conjunto ortonormal $ \\{u_1, \\ldots, u_k\\} $ com:\n",
    "\n",
    "$$\n",
    "\\mathop{\\mathrm{período}} \\{x_1, \\ldots, x_i\\}\n",
    "=\n",
    "\\mathop{\\mathrm{período}} \\{u_1, \\ldots, u_i\\}\n",
    "\\quad \\text{para} \\quad\n",
    "i = 1, \\ldots, k\n",
    "$$\n",
    "\n",
    "O processo de **ortogonalização de Gram-Schmidt** constrói um conjunto ortogonal $ \\{ u_1, u_2, \\ldots, u_n\\} $\n",
    "\n",
    "Uma descrição desse procedimento é a seguinte:\n",
    "\n",
    "- Para $ i = 1, \\ldots, k $, formar $ S_i := \\mathop{\\mathrm{período}}\\{x_1, \\ldots, x_i\\} $ e $ S_i^{\\perp} $  \n",
    "- Defina $ v_1 = x_1 $  \n",
    "- Para $ i \\geq 2 $ defina $ v_i := \\hat E_{S_{i-1}^{\\perp}} x_i $ e $ u_i := v_i / \\| v_i \\| $  \n",
    "\n",
    "\n",
    "A sentença $ u_1, \\ldots, u_k $ tem as propriedades declaradas\n",
    "\n",
    "Uma construção da ortogonalização de Gram-Schmidt é uma ideia-chave por trás do filtro Kalman descrito em [Uma primeira olhada no filtro Kalman](https://julia.quantecon.org/tools_and_techniques/kalman.html)\n",
    "\n",
    "Em alguns exercícios abaixo, você é solicitado a implementar esse algoritmo e testá-lo usando projeção."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição QR\n",
    "\n",
    "O resultado a seguir usa o algoritmo anterior para produzir uma decomposição útil.\n",
    "\n",
    "**Teorema.** Se $ X $ is $ n \\times k $ com colunas linearmente independentes, então existe uma fatoração $ X = Q R $ onde\n",
    "\n",
    "- $ R $ é $ k \\times k $, triângulo superior e não singular\n",
    "- $ Q $ é $ n \\times k $ com colunas ortonormais  \n",
    "\n",
    "\n",
    "Esboço da Prova: Deixe\n",
    "\n",
    "- $ x_j := col_j (X) $  \n",
    "- $ \\{u_1, \\ldots, u_k\\} $ ser ortonormal com o mesmo período como $ \\{x_1, \\ldots, x_k\\} $ (a ser construído usando Gram-Schmidt)  \n",
    "- $ Q $ ser formado a partir de cols $ u_i $  \n",
    "\n",
    "\n",
    "Desde $ x_j \\in \\mathop{\\mathrm{período}}\\{u_1, \\ldots, u_j\\} $, temos\n",
    "\n",
    "$$\n",
    "x_j = \\sum_{i=1}^j \\langle u_i, x_j  \\rangle u_i\n",
    "\\quad \\text{para } j = 1, \\ldots, k\n",
    "$$\n",
    "\n",
    "Algumas reorganizações dão $ X = Q R $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Linear via Decomposição QR\n",
    "\n",
    "Para as matrizes $ X $ e $ y $ que superdetermina $ beta $ na equação do sistema linear $ y = X \\beta $, encontramos o aproximador dos mínimos quadrados $ \\hat \\beta = (X' X)^{-1} X' y $\n",
    "\n",
    "Usando a decomposição QR $ X = Q R $ dá\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\hat \\beta\n",
    "    & = (R'Q' Q R)^{-1} R' Q' y \\\\\n",
    "    & = (R' R)^{-1} R' Q' y \\\\\n",
    "    & = R^{-1} (R')^{-1} R' Q' y\n",
    "        = R^{-1} Q' y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Rotinas numéricas, nesse caso, usariam a forma alternativa $ R \\hat \\beta = Q' y $ e substituição anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Mostre que, para qualquer subespaço linear $ S \\subset \\mathbb{R}^n $,  $ S \\cap S^{\\perp} = \\{0\\} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Deixe $ P = X (X' X)^{-1} X' $ e deixe $ M = I - P $.  Mostre que\n",
    "$ P $ e $ M $ são ambas idempotentes e simetricas. Você pode dar\n",
    "intuição de por que eles deveriam ser idempotentes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3\n",
    "\n",
    "Usando a ortogonalização de Gram-Schmidt, produza uma projeção linear de $ y $ para o espaço da coluna de $ X $ e verifique isso usando a projeção da matriz $ P := X (X' X)^{-1} X' $ e também usando a decomposição QR, onde:\n",
    "\n",
    "$$\n",
    "y :=\n",
    "\\left(\n",
    "\\begin{array}{c}\n",
    "    1 \\\\\n",
    "    3 \\\\\n",
    "    -3\n",
    "\\end{array}\n",
    "\\right),\n",
    "\\quad\n",
    "$$\n",
    "\n",
    "e\n",
    "\n",
    "$$\n",
    "X :=\n",
    "\\left(\n",
    "\\begin{array}{cc}\n",
    "    1 &  0  \\\\\n",
    "    0 & -6 \\\\\n",
    "    2 &  2\n",
    "\\end{array}\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soluções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Se $ x \\in S $ e $ x \\in S^\\perp $, então nós temos em particular\n",
    "que $ \\langle x, x \\rangle = 0 $. Mas então $ x = 0 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2\n",
    "\n",
    "Simetria e idempotência de $ M $ e $ P $ pode ser estabelecida\n",
    "usando regras padrão para álgebra matricial. A intuição por trás da idempotência de $ M $ e $ P $ é que ambas são projeções ortogonais. Depois que um ponto é projetado em um determinado subespaço, a aplicação de\n",
    "a projeção novamente não faz diferença. (Um ponto dentro do subespaço\n",
    "não é deslocado por projeção ortogonal para esse espaço porque é\n",
    "já é o ponto mais próximo do subespaço a si próprio.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3\n",
    "\n",
    "Aqui está uma função que calcula os vetores ortonormais usando o GS\n",
    "algoritmo dado na aula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: On Windows, creating file symlinks requires Administrator privileges\n",
      "└ @ Base.Filesystem file.jl:848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mActivated\u001b[0m C:\\Users\\cliente\\Downloads\\Project.toml\u001b[39m\n",
      "\u001b[36m\u001b[1mInfo\u001b[0m quantecon-notebooks-julia 0.4.0 activated, 0.5.0 requested\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "using InstantiateFromURL\n",
    "github_project(\"QuantEcon/quantecon-notebooks-julia\", version = \"0.5.0\", instantiate = true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gram_schmidt (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gram_schmidt(X)\n",
    "\n",
    "    U = similar(X, Float64) # para robustez\n",
    "\n",
    "    function normalized_orthogonal_projection(b, Z)\n",
    "        # projeto no complemento ortogonal da extensão de coluna de Z \n",
    "        orthogonal = I - Z * inv(Z'Z) * Z'\n",
    "        projection = orthogonal * b\n",
    "        # normaliza\n",
    "        return projection / norm(projection)\n",
    "    end\n",
    "\n",
    "    for col in 1:size(U, 2)\n",
    "        # configure\n",
    "        b = X[:,col]       # vetor que vamos projetar\n",
    "        Z = X[:,1:col - 1] # primeiro i-1 colunas X\n",
    "        U[:,col] = normalized_orthogonal_projection(b, Z)\n",
    "    end\n",
    "\n",
    "    return U\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui estão as matrizes com as quais trabalharemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "y = [1, 3, -3]\n",
    "X = [1 0; 0 -6; 2 2];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro vamos fazer uma projeção comum de  $ y $ na base medida \n",
    "pelas colunas de $ X $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.5652173913043479\n",
       "  3.2608695652173916\n",
       " -2.217391304347826 "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py1 = X * inv(X'X) * X' * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos ortogonalizar primeiro, usando Gram–Schmidt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       " 0.447214  -0.131876\n",
       " 0.0       -0.989071\n",
       " 0.894427   0.065938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = gram_schmidt(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos projetar usando a base ortonormal e ver se obtemos a mesma coisa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.5652173913043477\n",
       "  3.2608695652173916\n",
       " -2.2173913043478257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py2 = U * U' * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado é o mesmo. Para concluir o exercício, obtemos uma base ortonormal por decomposição QR e projetamos mais uma vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×2 Array{Float64,2}:\n",
       " -0.447214  -0.131876\n",
       "  0.0       -0.989071\n",
       " -0.894427   0.065938"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q, R = qr(X)\n",
    "Q = Matrix(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " -0.5652173913043473\n",
       "  3.2608695652173907\n",
       " -2.2173913043478253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Py3 = Q * Q' * y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, o resultado é o mesmo."
   ]
  }
 ],
 "metadata": {
  "filename": "orth_proj.rst",
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  },
  "title": "Orthogonal Projections and Their Applications"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
