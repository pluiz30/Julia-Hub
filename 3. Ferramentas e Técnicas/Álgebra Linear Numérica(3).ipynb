{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='numerical-linear-algebra'></a>\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Álgebra Linear Numérica e Fatorizações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "- [Álgebra Linear Numérica e Fatorizações](#Álgebra-Linear-Numérica-e-Fatorizações)  \n",
    "  - [Resumo](#Resumo)  \n",
    "  - [Fatorizações](#Fatorizações)  \n",
    "  - [Cadeias de Markov em Tempo Contínuo (CMTC)](#Cadeias-de-Markov-em-Tempo-Contínuo-%28CMTC%29)  \n",
    "  - [Matrizes em Faixas](#Matrizes-em-Faixas)  \n",
    "  - [Detalhes da Implementação e Performance](#Detalhes-da-Implementação-e-Performance)  \n",
    "  - [Exercícios](#Exercícios)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Devidamente traduzido, revisado e adaptado do [QuantEcon](https://julia.quantecon.org/) pelos bolsistas CNPq Pedro Luiz H. Furtado e Jonas Aragão M. Corpes, sob a supervisão do Prof. Christiano Penna, do CAEN/UFC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> >Você não pode aprender muita álgebra linear. – Benedict Gross"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Nesta palestra, examinamos a estrutura de matrizes e operadores lineares (por exemplo, densos, esparsos, simétricos, tridiagonais, em faixas) e discutimos como a estrutura pode ser explorada para aumentar radicalmente o desempenho da solução de grandes problemas.\n",
    "\n",
    "Desenvolvemos aplicativos discutidos em aulas anteriores: [álgebra linear](https://julia.quantecon.org/linear_algebra.html), [projeções ortogonais](https://julia.quantecon.org/orth_proj.html) e [Cadeias de Markov](https://julia.quantecon.org/finite_markov.html).\n",
    "\n",
    "Os métodos nesta seção são chamados de métodos diretos e são qualitativamente similares à realização da eliminação gaussiana para fatorar matrizes e resolver sistemas de equações. Em [métodos iterativos e esparsidade](https://julia.quantecon.org/iterative_methods_sparsity.html), examinamos uma abordagem diferente, usando algoritmos iterativos, nos quais podemos pensar em operadores lineares mais gerais.\n",
    "\n",
    "A lista de pacotes especializados para essas tarefas é enorme e crescente, mas algumas das organizações importantes a\n",
    "ver são [JuliaMatrices](https://github.com/JuliaMatrices), [JuliaSparse](https://github.com/JuliaSparse) e [JuliaMath](https://github.com/JuliaMath)\n",
    "\n",
    "* NOTA *: Como esta seção usa técnicas avançadas de Julia, você pode revisar a programação de despacho múltiplo e genérico na introdução aos tipos e considerar um estudo mais aprofundado sobre [programação genérica](https://julia.quantecon.org/../more_julia/generic_programming.html).\n",
    "\n",
    "O tema desta palestra e a álgebra linear numérica em geral se resume a três princípios:\n",
    "\n",
    "1. **Identificar a estrutura** (por exemplo, [simétrica, esparsa, diagonal, etc.](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/index.html#Special-matrices-1)) de matrizes para usar **algoritmos especializados**;\n",
    "2. **Não perca a estrutura** aplicando operações de álgebra linear incorretas nos horários errados (por exemplo, matriz esparsa se tornando densa), e\n",
    "3. Procure entender a **complexidade computacional** de cada algoritmo, dada a estrutura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide-output": true
   },
   "outputs": [],
   "source": [
    "using InstantiateFromURL\n",
    "github_project(\"QuantEcon/quantecon-notebooks-julia\", version = \"0.5.0\")\n",
    "# github_project(\"QuantEcon/quantecon-notebooks-julia\", version = \"0.5.0\", instantiate = true) # uncomment to force package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide-output": true
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, Statistics, BenchmarkTools, SparseArrays, Random\n",
    "Random.seed!(42);  # seed random numbers for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexidade computacional\n",
    "\n",
    "Pergunte a si mesmo se o seguinte é uma operação **computacionalmente cara** à medida que o tamanho da matriz **aumenta**\n",
    "\n",
    "- Multiplicando duas matrizes?\n",
    "  \n",
    "  - *Resposta*: Depende. Multiplicar 2 matrizes diagonais é trivial.\n",
    "  \n",
    "- Resolvendo um sistema linear de equações?\n",
    "  \n",
    "  - *Resposta*: Depende. Se a matriz é a identidade, a solução é o próprio vetor.\n",
    "  \n",
    "- Encontrando os autovalores de uma matriz?\n",
    "  \n",
    "  - *Resposta*: Depende. Os autovalores de uma matriz triangular são a diagonal.\n",
    "  \n",
    "\n",
    "\n",
    "Como o objetivo desta seção é avançar para métodos numéricos com sistemas grandes, precisamos entender quão bem os algoritmos escalam com o tamanho de matrizes / vetores / etc. Isso é conhecido como [complexidade computacional](https://en.wikipedia.org/wiki/Computational_complexity). Como vimos na resposta às perguntas acima, o algoritmo - e, portanto, a complexidade computacional - muda com base na estrutura da matriz.\n",
    "\n",
    "Embora essa noção de complexidade possa funcionar em vários níveis, como o número de [dígitos significativos](https://en.wikipedia.org/wiki/Computational_complexity_of_mathematics_operations#Arithmetic_functions) para operações matemáticas básicas), a quantidade de memória e armazenamento necessários ou a quantidade de tempo - normalmente focaremos na complexidade do tempo.\n",
    "\n",
    "Para complexidade do tempo, o tamanho $ N $ geralmente é a dimensionalidade do problema, embora, ocasionalmente, a chave seja o número de não-zeros na matriz ou a largura das bandas. Para nossas aplicações, a complexidade do tempo é considerada como o número de operações de ponto flutuante (por exemplo, adicionar, multiplicar etc.) necessárias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notação\n",
    "\n",
    "A complexidade dos algoritmos é tipicamente escrita na notação [Big O](https://en.wikipedia.org/wiki/Big_O_notation) que fornece limites para a escala.\n",
    "\n",
    "Formalmente, se o número de operações necessárias para um tamanho de problema $ N $ for $ f (N) $, podemos escrever isso como $ f (N) = O (g (N)) $ por alguns $ g (N) $ - tipicamente um polinômio.\n",
    "\n",
    "A interpretação é que existem algumas constantes $ M $ e $ N_0 $ tais que\n",
    "\n",
    "$$\n",
    "f(N) \\leq M g(N), \\text{ for } N > N_0\n",
    "$$\n",
    "\n",
    "Por exemplo, a complexidade de encontrar uma decomposição LU de uma matriz densa é $ O (N ^ 3) $, que deve ser lida como uma constante onde eventualmente, o número de operações de ponto flutuante necessário decompõe uma matriz de tamanho $ N \\times N $ cresce cubicamente.\n",
    "\n",
    "Lembre-se de que esses são resultados assintóticos destinados a entender a escala do problema, e a constante pode ser importante para um dado tamanho fixo.\n",
    "\n",
    "Por exemplo, o número de operações necessárias para uma [decomposição da LU](https://en.wikipedia.org/wiki/LU_decomposition#Algorithms) de uma matriz densa de $ N \\times N $ é $ f (N) = \\frac {2} {3} N ^ 3 $, ignorando os $ N ^ 2 $ e os termos inferiores. Outros métodos para resolver um sistema linear podem ter constantes diferentes de proporcionalidade, mesmo que tenham a mesma escala $ O (N ^ 3) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regras de complexidade computacional\n",
    "\n",
    "Às vezes, você precisará pensar em como [combinar algoritmos](https://en.wikipedia.org/wiki/Big_O_notation#Properties) altera a complexidade. Por exemplo, se você usar:\n",
    "\n",
    "1. Uma operação $ O (N ^ 3) $ $ P $ vezes, simplesmente muda a constante. A complexidade permanece $ O (N ^ 3) $\n",
    "2. Uma operação de $ O (N ^ 3) $ e outra operação de $ O (N ^ 2) $ one, então você leva o máximo. A complexidade permanece $ O (N ^ 3) $\n",
    "3. Uma repetição de uma operação de $ O (N) $ que usa ela própria um $ O (N) $ um, você pega o produto. A complexidade se torna $ O (N ^ 2) $\n",
    "\n",
    "\n",
    "Com isso, temos uma palavra importante de cautela: a multiplicação densa de matrizes é uma [operação cara](https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations#Matrix_algebra) para matrizes não estruturadas e a versão básica é $ O ( N ^ 3) $.\n",
    "\n",
    "Obviamente, as bibliotecas modernas usam algoritmos [altamente ajustados e numericamente estáveis](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm) para multiplicar matrizes e explorar a arquitetura do computador, o cache de memória, etc., mas isso simplesmente reduz a constante proporcionalidade e permanecem $ O (N ^ 3) $.\n",
    "\n",
    "Uma conseqüência é que, como muitos algoritmos requerem multiplicação matriz-matriz, muitas vezes não é possível ficar abaixo dessa ordem sem mais estrutura matricial.\n",
    "\n",
    "Ou seja, alterar a constante de proporcionalidade para um determinado tamanho pode ajudar, mas, para alcançar um escalonamento mais alto, é necessário identificar a estrutura da matriz (por exemplo, tridigonal, esparsa etc.) e garantir que suas operações não a percam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perdendo estrutura\n",
    "\n",
    "Como primeiro exemplo de uma matriz estruturada, considere uma [matriz esparsa](https://docs.julialang.org/en/v1/stdlib/SparseArrays/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnz(A) = 47\n",
      "nnz(invA) = 100\n"
     ]
    }
   ],
   "source": [
    "A = sprand(10, 10, 0.45)  # 10x10 esparso aleatório, 45% preenchido com zeros\n",
    "\n",
    "@show nnz(A)  # conta o número de não-nulos\n",
    "invA = sparse(inv(Array(A)))  # julia não inverte esparso, então converta para denso com matriz.\n",
    "@show nnz(invA);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse aumento de menos de 50 a 100% de densidade demonstra que uma escarsidade significativa pode ser perdida ao calcular um inverso.\n",
    "\n",
    "Os resultados podem ser ainda mais extremos. Considere uma matriz tridiagonal de tamanho $ N \\times N $\n",
    "que pode resultar de uma cadeia de Markov ou discretização de um processo de difusão,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Tridiagonal{Float64,Array{Float64,1}}:\n",
       " 0.8  0.2   ⋅    ⋅    ⋅ \n",
       " 0.1  0.8  0.1   ⋅    ⋅ \n",
       "  ⋅   0.1  0.8  0.1   ⋅ \n",
       "  ⋅    ⋅   0.1  0.8  0.1\n",
       "  ⋅    ⋅    ⋅   0.2  0.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "A = Tridiagonal([fill(0.1, N-2); 0.2], fill(0.8, N), [0.2; fill(0.1, N-2);])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O número de não-zeros aqui é de aproximadamente US $ 3 N $, linear, o que pode ser bem escalonado para matrizes enormes que chegam a milhões ou bilhões\n",
    "\n",
    "Mas considere o inverso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       "  1.29099      -0.327957     0.0416667  -0.00537634   0.000672043\n",
       " -0.163978      1.31183     -0.166667    0.0215054   -0.00268817 \n",
       "  0.0208333    -0.166667     1.29167    -0.166667     0.0208333  \n",
       " -0.00268817    0.0215054   -0.166667    1.31183     -0.163978   \n",
       "  0.000672043  -0.00537634   0.0416667  -0.327957     1.29099    "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, a matriz é totalmente densa e possui $ N ^ 2 $ não zeros.\n",
    "\n",
    "Isso também se aplica à operação $ A 'A $ se formar as equações normais dos mínimos lineares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnz(A) / 20 ^ 2 = 0.2825\n",
      "nnz(A' * A) / 21 ^ 2 = 0.800453514739229\n"
     ]
    }
   ],
   "source": [
    "A = sprand(20, 21, 0.3)\n",
    "@show nnz(A)/20^2\n",
    "@show nnz(A'*A)/21^2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que uma matriz densa de 30% fica quase densa depois que o produto é retirado.\n",
    "\n",
    "*A escassez/estrutura não é apenas para armazenamento*: Às vezes, o tamanho da matriz pode se tornar importante (por exemplo, uma matriz tridiagonal de 1 milhão por 1 milhão precisa armazenar 3 milhões de números (ou seja, cerca de 6 MB de memória), onde uma densa requer 1 trilhão ( ou seja, cerca de 1 TB de memória).\n",
    "\n",
    "Mas, como veremos, o principal objetivo de considerar a dispersão e a estrutura da matriz é que ela permite algoritmos especializados que normalmente\n",
    "têm uma ordem computacional mais baixa que a densa não estruturada, ou mesmo operações esparsas não estruturadas.\n",
    "\n",
    "Primeiro, crie funções convenientes para comparar comparadores lineares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benchmark_solve (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "function benchmark_solve(A, b)\n",
    "    println(\"A\\\\b for typeof(A) = $(string(typeof(A)))\")\n",
    "    @btime $A \\ $b\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, retire a estrutura para ver o impacto no desempenho,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\\b for typeof(A) = Tridiagonal{Float64,Array{Float64,1}}\n",
      "  27.075 μs (9 allocations: 47.75 KiB)\n",
      "A\\b for typeof(A) = SparseMatrixCSC{Float64,Int64}\n",
      "  702.513 μs (69 allocations: 1.06 MiB)\n",
      "A\\b for typeof(A) = Array{Float64,2}\n",
      "  28.193 ms (5 allocations: 7.65 MiB)\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "b = rand(N)\n",
    "A = Tridiagonal([fill(0.1, N-2); 0.2], fill(0.8, N), [0.2; fill(0.1, N-2);])\n",
    "A_sparse = sparse(A)  # estrutura tridiagonal esparsa, mas perdida\n",
    "A_dense = Array(A)    # descartando a estrutura de escarsidade, densidade 1000x1000\n",
    "\n",
    "# solução de referência para A x = b\n",
    "benchmark_solve(A, b)\n",
    "benchmark_solve(A_sparse, b)\n",
    "benchmark_solve(A_dense, b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este exemplo mostra o que está em jogo: o uso de um tridiagonal estruturado pode ser 10 a 20 vezes mais rápido do que o uso de uma matriz esparsa 100x mais rápida do que\n",
    "usando uma matriz densa.\n",
    "\n",
    "De fato, a diferença se torna mais extrema à medida que as matrizes crescem. Resolver um sistema tridiagonal é $ O (N) $ enquanto o de uma matriz densa sem nenhuma estrutura é $ O (N ^ 3) $. A complexidade de uma solução esparsa é mais complicada e aumenta em parte pelo `nnz (N)`, ou seja, o número de não-zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplicação de matriz\n",
    "\n",
    "Enquanto escrevemos multiplicações matriciais em nossa álgebra com abandono, na prática a operação é muito ruim, sem nenhuma estrutura matricial.\n",
    "\n",
    "A multiplicação de matrizes é tão importante para os computadores modernos que a constante de escala é pequena usando pacotes adequados, mas a ordem ainda é de $ O (N ^ 3) $ na prática.\n",
    "\n",
    "A multiplicação de matriz esparsa, por outro lado, é $ O (N M_A M_B) $, onde $ M_A $ é o número de não zeros por linha de $ A $ e $ B $ é o número de não zeros por coluna de $ B $ .\n",
    "\n",
    "Pelas regras da ordem computacional, isso significa que qualquer algoritmo que exija uma multiplicação de matrizes densas requer pelo menos $ O (N ^ 3) $ operação.\n",
    "\n",
    "A outra questão importante é qual é a estrutura da matriz resultante. Por exemplo, multiplicando um triangular superior por um triangular inferior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 UpperTriangular{Float64,Array{Float64,2}}:\n",
       " 0.299976  0.176934  0.0608682  0.20465   0.409653 \n",
       "  ⋅        0.523923  0.127154   0.512531  0.235328 \n",
       "  ⋅         ⋅        0.600588   0.682868  0.330638 \n",
       "  ⋅         ⋅         ⋅         0.345419  0.0312986\n",
       "  ⋅         ⋅         ⋅          ⋅        0.471043 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 5\n",
    "U = UpperTriangular(rand(N,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Adjoint{Float64,UpperTriangular{Float64,Array{Float64,2}}}:\n",
       " 0.299976   0.0       0.0       0.0        0.0     \n",
       " 0.176934   0.523923  0.0       0.0        0.0     \n",
       " 0.0608682  0.127154  0.600588  0.0        0.0     \n",
       " 0.20465    0.512531  0.682868  0.345419   0.0     \n",
       " 0.409653   0.235328  0.330638  0.0312986  0.471043"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = U'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the product is fully dense (e.g. think of a cholesky multiplied by itself to produce a covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Array{Float64,2}:\n",
       " 0.0899855  0.0530758  0.018259   0.0613901  0.122886\n",
       " 0.0530758  0.305801   0.0773883  0.304736   0.195775\n",
       " 0.018259   0.0773883  0.380579   0.487749   0.253435\n",
       " 0.0613901  0.304736   0.487749   0.890193   0.441042\n",
       " 0.122886   0.195775   0.253435   0.441042   0.555378"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L * U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por outro lado, um tridiagonal vezes uma diagonal ainda é um tridiagonal - e pode usar algoritmos especializados $ O (N) $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Tridiagonal{Float64,Array{Float64,1}}:\n",
       " 0.0156225  0.00390564   ⋅           ⋅          ⋅        \n",
       " 0.0436677  0.349342    0.0436677    ⋅          ⋅        \n",
       "  ⋅         0.0213158   0.170526    0.0213158   ⋅        \n",
       "  ⋅          ⋅          0.00790566  0.0632453  0.00790566\n",
       "  ⋅          ⋅           ⋅          0.19686    0.787442  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Tridiagonal([fill(0.1, N-2); 0.2], fill(0.8, N), [0.2; fill(0.1, N-2);])\n",
    "D = Diagonal(rand(N))\n",
    "D * A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatorizações\n",
    "\n",
    "Quando você diz a um analista numérico que está resolvendo um sistema linear usando métodos diretos, a primeira pergunta é \"qual fatoração?\".\n",
    "\n",
    "Assim como você pode fatorar um número (por exemplo, $ 6 = 3 \\ vezes 2 $), você pode fatorar uma matriz como o produto de outras\n",
    "matrizes convenientes (por exemplo, $ A = LU $ ou $ A = QR $, onde $ L, U, Q, $ e $ R $ têm propriedades como triangulares ou [ortogonais](https://en.wikipedia.org/wiki/Orthogonal_matrix), etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invertendo matrizes\n",
    "\n",
    "No papel, como o [Teorema da matriz invertível](https://en.wikipedia.org/wiki/Invertible_matrix#The_invertible_matrix_theorem) nos diz que uma solução única é equivalente a $ A $ ser invertível, geralmente escrevemos a solução para $ A x = b $ como\n",
    "\n",
    "$$\n",
    "x = A^{-1} b\n",
    "$$\n",
    "\n",
    "E se não usarmos (diretamente) uma fatoração?\n",
    "\n",
    "Pegue um sistema linear simples de uma matriz densa,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 0.5682240701809245 \n",
       " 0.40245385575255055\n",
       " 0.1825995192132288 \n",
       " 0.06160128039631019"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "A = rand(N,N)\n",
    "b = rand(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No papel, resolvemos $ A x = b $ invertendo a matriz,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.0339069840407679\n",
       "  0.7988200873225003\n",
       "  0.9963711951331815\n",
       " -0.9276352098500461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = inv(A) * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veremos ao longo, matrizes inversas devem ser usadas para a teoria, não para o código. O conselho clássico de que você nunca deve [inverter uma matriz](https://www.johndcook.com/blog/2010/01/19/dont-invert-that-matrix) pode ser [um pouco exagerado](https://arxiv.org/abs/1201.6035), mas geralmente é um bom conselho.\n",
    "\n",
    "Resolver um sistema invertendo uma matriz é sempre um pouco mais lento, potencialmente menos preciso, e às vezes perde esparsidade crucial em comparação ao uso de fatorações. Além disso, os métodos usados pelas bibliotecas para inverter matrizes são freqüentemente as mesmas fatorações usadas para calcular um sistema de equações.\n",
    "\n",
    "Mesmo se você precisar resolver um sistema com a mesma matriz várias vezes, é melhor fatorar a matriz e usar o solucionador em vez de calcular um inverso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  399.645 μs (68 allocations: 205.28 KiB)\n",
      "  345.648 μs (96 allocations: 155.59 KiB)\n",
      "  160.660 μs (6 allocations: 102.63 KiB)\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "A = rand(N,N)\n",
    "M = 30\n",
    "B = rand(N,M)\n",
    "function solve_inverting(A, B)\n",
    "    A_inv = inv(A)\n",
    "    X = similar(B)\n",
    "    for i in 1:size(B,2)\n",
    "        X[:,i] = A_inv * B[:,i]\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "function solve_factoring(A, B)\n",
    "    X = similar(B)\n",
    "    A = factorize(A)\n",
    "    for i in 1:size(B,2)\n",
    "        X[:,i] = A \\ B[:,i]\n",
    "    end\n",
    "    return X\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "@btime solve_inverting($A, $B)\n",
    "@btime solve_factoring($A, $B)\n",
    "\n",
    "# melhor ainda, use o recurso embutido para vários RHS\n",
    "@btime $A \\ $B;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrizes Triangulares e Substituição Trás/Frente\n",
    "\n",
    "Algumas matrizes já estão em uma forma conveniente e não requerem mais fatoração.\n",
    "\n",
    "Por exemplo, considere resolver um sistema com uma matriz `UpperTriangular`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 UpperTriangular{Float64,Array{Float64,2}}:\n",
       " 1.0  2.0  3.0\n",
       "  ⋅   5.0  6.0\n",
       "  ⋅    ⋅   9.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [1.0, 2.0, 3.0]\n",
    "U = UpperTriangular([1.0 2.0 3.0; 0.0 5.0 6.0; 0.0 0.0 9.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse sistema é especialmente fácil de resolver usando a [substituição posterior](https://en.wikipedia.org/wiki/Triangular_matrix#Forward_and_back_substitution). Em particular, $ x_3 = b_3 / U_{33}, x_2 = (b_2 - x_3 U_{23})/U_{22} $, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0               \n",
       " 0.0               \n",
       " 0.3333333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U \\ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um `LowerTriangular` tem propriedades semelhantes e pode ser resolvido com substituição direta.\n",
    "\n",
    "A ordem computacional de substituição traseira e substituição direta é $ O (N ^ 2) $ para matrizes densas. Esses algoritmos rápidos são um dos principais motivos pelos quais as fatorações objetivam estruturas triangulares.\n",
    "\n",
    "\n",
    "<a id='jl-decomposition'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição LU\n",
    "\n",
    "As decomposições de $ LU $ encontram um $ L $ triangular inferior e um $ U $ triangular superior, de modo que $ L U = A $.\n",
    "\n",
    "Para uma matriz densa geral sem qualquer outra estrutura (isto é, não conhecida por ser simétrica, tridiagonal etc.), esta é a abordagem padrão para resolver um sistema e explorar a velocidade da substituição para trás e para frente usando a fatoração.\n",
    "\n",
    "A ordem computacional da decomposição da LU em si para uma matriz densa é $ O (N ^ 3) $ - o mesmo que a eliminação gaussiana, mas tende a\n",
    "ter um termo constante melhor do que outros (por exemplo, metade do número de operações da decomposição QR). Para estruturado\n",
    "ou matrizes esparsas, essa ordem cai.\n",
    "\n",
    "Podemos ver qual algoritmo Julia usará para o operador `\\` observando a função `fatorize` de um dado\n",
    "matriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU{Float64,Array{Float64,2}}\n",
       "L factor:\n",
       "4×4 Array{Float64,2}:\n",
       " 1.0       0.0       0.0       0.0\n",
       " 0.563082  1.0       0.0       0.0\n",
       " 0.730109  0.912509  1.0       0.0\n",
       " 0.114765  0.227879  0.115228  1.0\n",
       "U factor:\n",
       "4×4 Array{Float64,2}:\n",
       " 0.79794  0.28972   0.765939   0.496278\n",
       " 0.0      0.82524   0.23962   -0.130989\n",
       " 0.0      0.0      -0.447888   0.374303\n",
       " 0.0      0.0       0.0        0.725264"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "A = rand(N,N)\n",
    "b = rand(N)\n",
    "\n",
    "Af = factorize(A)  # escolhe a fatoração correta, LU aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse caso, ele fornece uma fatoração de $ L $ e $ U $ (com [pivotante](https://en.wikipedia.org/wiki/LU_decomposition#LU_factorization_with_full_pivoting)).\n",
    "\n",
    "Com a fatoração completa, podemos resolver diferentes lados `b 'do lado direito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.49842605495731557\n",
       " -0.11835721499695576\n",
       "  1.5055538550184817 \n",
       "  0.07694455957797537"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Af \\ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.6456780666059364\n",
       " -0.2601515737654759\n",
       "  1.116889566296631 \n",
       "  0.5405293106660054"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2 = rand(N)\n",
    "Af \\ b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na prática, a decomposição também inclui um $ P $ é uma [matriz de permutação](https://en.wikipedia.org/wiki/Permutation_matrix) como\n",
    "que $ P A = L U $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Af.P * A ≈ Af.L * Af.U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também podemos calcular diretamente uma decomposição `lu` sem a rotação,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU{Float64,Array{Float64,2}}\n",
       "L factor:\n",
       "4×4 Array{Float64,2}:\n",
       " 1.0       0.0       0.0       0.0\n",
       " 0.730109  1.0       0.0       0.0\n",
       " 0.563082  1.09588   1.0       0.0\n",
       " 0.114765  0.249728  0.122733  1.0\n",
       "U factor:\n",
       "4×4 Array{Float64,2}:\n",
       " 0.79794  0.28972    0.765939   0.496278\n",
       " 0.0      0.753039  -0.229233   0.254774\n",
       " 0.0      0.0        0.490832  -0.410191\n",
       " 0.0      0.0        0.0        0.725264"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L, U = lu(A, Val(false))  # o Val(false) fornece solução sem matrizes de permutação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E nós podemos verificar a decomposição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A ≈ L * U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver mais ou menos como o solucionador funciona, observe que podemos escrever o problema $ A x = b $ como $ L U x = b $. Deixe $ U x = y $, que quebra o problema em dois subproblemas.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L y &= b\\\\\n",
    "U x &= y\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Como vimos acima, esta é a solução para dois sistemas triangulares, que podem ser eficientemente feitos com a substituição para frente ou para trás em operações de $ O (N ^ 2) $.\n",
    "\n",
    "Para demonstrar isso, primeiro use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       "  0.759344042755733  \n",
       " -0.4146467815590597 \n",
       "  0.707411438334498  \n",
       "  0.05580508465599857"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = L \\ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = U \\ y\n",
    "x ≈ A \\ b  # verifica idêntico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A decomposição da LU também possui algoritmos especializados para matrizes estruturadas, como um `Tridiagonal`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LU{Float64,Tridiagonal{Float64,Array{Float64,1}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "b = rand(N)\n",
    "A = Tridiagonal([fill(0.1, N-2); 0.2], fill(0.8, N), [0.2; fill(0.1, N-2);])\n",
    "factorize(A) |> typeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa fatoração é a chave para o desempenho do `A \\ b` neste caso. Para matrizes tridiagonais, a decomposição da LU é $ O (N ^ 2) $.\n",
    "\n",
    "Finalmente, assim como uma matriz densa sem estrutura usa uma decomposição de LU para resolver um sistema, os solucionadores esparsos também:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuiteSparse.UMFPACK.UmfpackLU{Float64,Int64}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sparse = sparse(A)\n",
    "factorize(A_sparse) |> typeof  # soltando a estrutura tridiagonal para se tornar esparsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\\b for typeof(A) = Tridiagonal{Float64,Array{Float64,1}}\n",
      "  27.466 μs (9 allocations: 47.75 KiB)\n",
      "A\\b for typeof(A) = SparseMatrixCSC{Float64,Int64}\n",
      "  702.174 μs (69 allocations: 1.06 MiB)\n"
     ]
    }
   ],
   "source": [
    "benchmark_solve(A, b)\n",
    "benchmark_solve(A_sparse, b);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a escarsidade, a ordem computacional está relacionada ao número de não-zeros, e não ao tamanho da própria matriz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição de Cholesky \n",
    "\n",
    "Para matrizes reais, simétricas [definitivas](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix), uma decomposição de Cholesky é um exemplo especializado da decomposição da LU em que $ L = U '$.\n",
    "\n",
    "O Cholesky é diretamente útil por si só (por exemplo, [Controle clássico com álgebra linear](https://julia.quantecon.org/../time_series_models/classical_filtering.html)), mas também é uma fatoração eficiente para resolver o sistema definido positivo simétrico.\n",
    "\n",
    "Como sempre, a simetria permite algoritmos especializados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BunchKaufman{Float64,Array{Float64,2}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 500\n",
    "B = rand(N,N)\n",
    "A_dense = B' * B  # uma maneira fácil de gerar uma matriz definida positiva simétrica\n",
    "A = Symmetric(A_dense)  # sinalize a matriz como simétrica\n",
    "\n",
    "factorize(A) |> typeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, a decomposição $ A $ é de [Bunch-Kaufman](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/index.html#LinearAlgebra.bunchkaufman) em vez de um\n",
    "Cholesky, porque o Julia não sabe que a matriz é definitiva positiva. Podemos fatorar manualmente com um Cholesky:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cholesky{Float64,Array{Float64,2}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cholesky(A) |> typeof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referenciando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\\b for typeof(A) = Symmetric{Float64,Array{Float64,2}}\n",
      "  4.557 ms (8 allocations: 2.16 MiB)\n",
      "A\\b for typeof(A) = Array{Float64,2}\n",
      "  6.133 ms (5 allocations: 1.92 MiB)\n",
      "  3.065 ms (7 allocations: 1.91 MiB)\n"
     ]
    }
   ],
   "source": [
    "b = rand(N)\n",
    "cholesky(A) \\ b  # use a fatoração para resolver\n",
    "\n",
    "benchmark_solve(A, b)\n",
    "benchmark_solve(A_dense, b)\n",
    "@btime cholesky($A, check=false) \\ $b;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição QR\n",
    "\n",
    "Anteriormente, aprendemos sobre aplicações da ferramenta QR para resolver os mínimos quadrados lineares.\n",
    "\n",
    "Embora, em princípio, a solução para o problema dos mínimos quadrados\n",
    "\n",
    "$$\n",
    "\\min_x \\| Ax -b \\|^2\n",
    "$$\n",
    "\n",
    "seja $ x = (A'A)^{-1}A'b $, na prática, observe que $ A'A $ se torna denso e calcular o inverso raramente é uma boa idéia.\n",
    "\n",
    "A decomposição QR é uma decomposição $ A = Q R $ em que $ Q $ é uma matriz ortogonal (ou seja, $ Q'Q = Q Q '= I $) e $ R $ é\n",
    "uma matriz triangular superior.\n",
    "\n",
    "Dada a derivação anterior, mostramos que podemos escrever o problema dos mínimos quadrados como\n",
    "a solução para\n",
    "\n",
    "$$\n",
    "R x = Q' b\n",
    "$$\n",
    "\n",
    "Onde, como discutido acima, a estrutura triangular superior de $ R $ pode ser resolvida facilmente com substituição traseira.\n",
    "\n",
    "O operador `\\` resolve o problema dos mínimos quadrados lineares sempre que o `A` fornecido é retangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  0.4011747124872585\n",
       "  0.0736108001071848\n",
       " -0.2347806801272458"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "M = 3\n",
    "x_true = rand(3)\n",
    "\n",
    "A = rand(N,M) .+ randn(N)\n",
    "b = rand(N)\n",
    "x = A \\ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para usar manualmente a decomposição QR na resolução de mínimos quadrados lineares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q * R ≈ A = true\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  0.4011747124872585 \n",
       "  0.07361080010718478\n",
       " -0.2347806801272457 "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Af = qr(A)\n",
    "Q = Af.Q\n",
    "R = [Af.R; zeros(N - M, M)] # Pilha com zeros\n",
    "@show Q * R ≈ A\n",
    "x = R \\ Q'*b  # simplificar a solução QR par mínimos quadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso empilha o `R` com zeros, mas o algoritmo mais especializado não se multiplicaria diretamente dessa maneira.\n",
    "\n",
    "Em alguns casos, se uma LU não estiver disponível para uma estrutura de matriz específica, a fatoração QR também pode ser usada para resolver sistemas de equações (ou seja, não apenas LLS). Isso tende a ser cerca de 2x mais lento que a LU, mas é da mesma ordem computacional.\n",
    "\n",
    "Derivando a abordagem, onde agora podemos usar inverso, pois o sistema é quadrado e assumimos que $ A $ não era singular\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A x &= b\\\\\n",
    "Q R x &= b\\\\\n",
    "Q^{-1} Q R x &= Q^{-1} b\\\\\n",
    "R x &= Q' b\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Onde a última etapa usa esse $ Q ^ {- 1} = Q '$ para uma matriz ortogonal.\n",
    "\n",
    "Dada a decomposição, a solução para matrizes densas é de ordem computacional $ O (N ^ 2) $. Para ver isso, observe a ordem de cada operação.\n",
    "\n",
    "- Como $ R $ é uma matriz triangular superior, ele pode ser resolvido rapidamente através da substituição reversa com a ordem computacional $ O (N ^ 2) $\n",
    "- Uma operação de transposição é da ordem $ O (N ^ 2) $\n",
    "- Um produto vetor de matriz também é $ O (N ^ 2) $\n",
    "\n",
    "\n",
    "Em todos os casos, a ordem diminuiria dependendo do padrão de esparsidade da matriz (e da decomposição correspondente). Um dos principais benefícios de uma decomposição QR é que ela tende a manter a escarsidade.\n",
    "\n",
    "Sem implementar o processo completo, você pode formar um QR\n",
    "fatoração com `qr` e use-a para resolver um sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \\ b = [-1.478040941944558, 2.09875752634393, -0.6857071090150306, -0.16849538664184543, 2.012803045177841]\n",
      "qr(A) \\ b = [-1.4780409419445582, 2.09875752634393, -0.685707109015032, -0.16849538664184413, 2.0128030451778414]\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "A = rand(N,N)\n",
    "b = rand(N)\n",
    "@show A \\ b\n",
    "@show qr(A) \\ b;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposição espectral\n",
    "\n",
    "Uma decomposição espectral, também conhecida como [autodecomposição](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix), encontra todos os autovetores e autovalores para decompor uma matriz quadrada `A` de modo que\n",
    "\n",
    "$$\n",
    "A = Q \\Lambda Q ^ {- 1}\n",
    "$$\n",
    "\n",
    "onde $ Q $ é uma matriz composta pelos vetores próprios de $ A $ como colunas e $ \\Lambda $ é uma matriz diagonal dos valores próprios. Somente matrizes quadradas, [diagonalizáveis](https://en.wikipedia.org/wiki/Diagonalizable_matrix) têm uma composição automática (onde uma matriz não é diagonalizável se não tiver um conjunto completo de vetores próprios linearmente independentes).\n",
    "\n",
    "Em Julia, sempre que você solicita um conjunto completo de vetores próprios e valores próprios, ele se decompõe usando um algoritmo apropriado para o tipo de matriz. Por exemplo, matrizes simétricas, hermitianas ou tridiagonais possuem algoritmos especializados.\n",
    "\n",
    "Para ver isso,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.803627108839096e-15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Symmetric(rand(5, 5))  # matrizes simétricas tem autovalores/autovetores reais\n",
    "A_eig = eigen(A)\n",
    "Λ = Diagonal(A_eig.values)\n",
    "Q = A_eig.vectors\n",
    "norm(Q * Λ * inv(Q) - A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembre-se de que uma matriz real pode ter autovalores e autovetores complexos, portanto, se você tentar verificar `Q * Λ * inv (Q) - A` - mesmo para uma matriz definida positiva - pode não ser um número devido devido imprecisão numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cadeias de Markov em Tempo Contínuo (CMTC)\n",
    "\n",
    "Na palestra anterior sobre cadeias de Markov com tempo discreto, vimos que a probabilidade de transição\n",
    "entre o estado $ x $ e o estado $ y $ foi resumido pela matriz $ P (x, y): = \\mathbb P \\{X_ {t + 1} = y \\, | \\, X_t = x \\} $.\n",
    "\n",
    "Como uma breve introdução aos processos de tempo contínuos, considere o mesmo espaço de estado que no\n",
    "case: $ S $ um conjunto finito com $ n $ elementos $ \\{x_1, \\ldots, x_n \\} $.\n",
    "\n",
    "Uma **Cadeia de Markov** $ \\{X_t \\} $ em $ S $ é uma sequência de variáveis aleatórias em $ S $ que possuem a **Propriedade de Markov**.\n",
    "\n",
    "Em tempo contínuo, a [Propriedade de Markov](https://en.wikipedia.org/wiki/Markov_property) é mais complicada, mas intuitivamente é o mesmo que no caso de tempo discreto.\n",
    "\n",
    "Ou seja, conhecer o estado atual é suficiente para conhecer probabilidades para estados futuros. Ou, para realizações $ x (\\tau)\\ em S, \\tau \\leq t $,\n",
    "\n",
    "$$\n",
    "\\mathbb P \\{ X(t+s) = y  \\,|\\, X(t) = x, X(\\tau) = x(\\tau) \\text{ for } 0 \\leq \\tau \\leq t  \\} = \\mathbb P \\{ X(t+s) = y  \\,|\\, X(t) = x\\}\n",
    "$$\n",
    "\n",
    "Heuristicamente, considere um período de tempo $ t $ e um pequeno passo à frente $ \\Delta $. Então a probabilidade de fazer a transição do estado $ i $ para o estado $ j $ é\n",
    "\n",
    "$$\n",
    "\\mathbb P \\{ X(t + \\Delta) = j  \\,|\\, X(t) \\} = \\begin{cases} q_{ij} \\Delta + o(\\Delta) & i \\neq j\\\\\n",
    "                                                              1 + q_{ii} \\Delta + o(\\Delta) & i = j \\end{cases}\n",
    "$$\n",
    "\n",
    "onde $ q_ {ij} $ são parâmetros de “intensidade” que governam a taxa de transição, e $ o (\\Delta) $ é uma [pequena notação](https://en.wikipedia.org/wiki/Big_O_notation#Little-o_notation) Ou seja, $ \\lim _ {\\Delta \\ a 0} o (\\Delta) / \\Delta = 0 $.\n",
    "\n",
    "Assim como no caso discreto, podemos resumir esses parâmetros com uma matriz $ N \\times N $, $ Q \\ em R ^ {N \\times N} $.\n",
    "\n",
    "Lembre-se de que, no caso discreto, cada elemento é fracamente positivo e cada linha deve somar uma. Em vez disso, com um tempo contínuo, as linhas de $ Q $ somam zero, onde a diagonal contém o valor negativo de saltar do estado atual. Isso é\n",
    "\n",
    "- $ q_{ij} \\geq 0 $ para $ i \\neq j $  \n",
    "- $ q_{ii} \\leq 0 $  \n",
    "- $ \\sum_{j} q_{ij} = 0 $  \n",
    "\n",
    "\n",
    "A matriz $ Q $ é chamada matriz de intensidade ou gerador infinitesimal da cadeia de Markov. Por exemplo,\n",
    "\n",
    "$$\n",
    "Q = \\begin{bmatrix} -0.1 & 0.1  & 0 & 0 & 0 & 0\\\\\n",
    "                    0.1  &-0.2  & 0.1 &  0 & 0 & 0\\\\\n",
    "                    0 & 0.1 & -0.2 & 0.1 & 0 & 0\\\\\n",
    "                    0 & 0 & 0.1 & -0.2 & 0.1 & 0\\\\\n",
    "                    0 & 0 & 0 & 0.1 & -0.2 & 0.1\\\\\n",
    "                    0 & 0 & 0 & 0 & 0.1 & -0.1\\\\\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Nesse exemplo, as transições ocorrem apenas entre estados adjacentes com a mesma intensidade (exceto para um `` retorno '' dos estados inferior e superior).\n",
    "\n",
    "Implementando o $ Q $ usando sua estrutura tridiagonal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Tridiagonal{Float64,Array{Float64,1}}:\n",
       " -0.1   0.1    ⋅     ⋅     ⋅     ⋅ \n",
       "  0.1  -0.2   0.1    ⋅     ⋅     ⋅ \n",
       "   ⋅    0.1  -0.2   0.1    ⋅     ⋅ \n",
       "   ⋅     ⋅    0.1  -0.2   0.1    ⋅ \n",
       "   ⋅     ⋅     ⋅    0.1  -0.2   0.1\n",
       "   ⋅     ⋅     ⋅     ⋅    0.1  -0.1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "α = 0.1\n",
    "N = 6\n",
    "Q = Tridiagonal(fill(α, N-1), [-α; fill(-2α, N-2); -α], fill(α, N-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos usar o `Tridiagonal` para explorar a estrutura do problema.\n",
    "\n",
    "Considere um vetor de pagamento simples $ r $ associado a cada estado e uma taxa de desconto $ ρ $. Então podemos resolver para\n",
    "o valor presente descontado esperado de maneira semelhante ao caso de tempo discreto.\n",
    "\n",
    "$$\n",
    "\\rho v = r + Q v\n",
    "$$\n",
    "\n",
    "ou reorganizando levemente, resolvendo o sistema linear\n",
    "\n",
    "$$\n",
    "(\\rho I - Q) v = r\n",
    "$$\n",
    "\n",
    "Para o nosso exemplo, explorando a estrutura tridiagonal,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Tridiagonal{Float64,Array{Float64,1}}:\n",
       "  0.15  -0.1     ⋅      ⋅      ⋅      ⋅  \n",
       " -0.1    0.25  -0.1     ⋅      ⋅      ⋅  \n",
       "   ⋅    -0.1    0.25  -0.1     ⋅      ⋅  \n",
       "   ⋅      ⋅    -0.1    0.25  -0.1     ⋅  \n",
       "   ⋅      ⋅      ⋅    -0.1    0.25  -0.1 \n",
       "   ⋅      ⋅      ⋅      ⋅    -0.1    0.15"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = range(0.0, 10.0, length=N)\n",
    "ρ = 0.05\n",
    "\n",
    "A = ρ * I - Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que essa matriz $ A $ mantém a estrutura tridiagonal do problema, o que leva a uma solução eficiente para o problema linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Float64,1}:\n",
       "  38.15384615384615\n",
       "  57.23076923076923\n",
       "  84.92307692307693\n",
       " 115.07692307692311\n",
       " 142.76923076923077\n",
       " 161.84615384615384"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = A \\ r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O $ Q $ também é usado para calcular a evolução da cadeia de Markov, em analogia direta à evolução $ ψ_ {t + k} = ψ_t P ^ k $ com a matriz de transição $ P $ do caso discreto.\n",
    "\n",
    "No caso contínuo, isso se torna o sistema de equações diferenciais lineares\n",
    "\n",
    "$$\n",
    "\\dot{ψ}(t) = Q(t)^T ψ(t)\n",
    "$$\n",
    "\n",
    "dada a condição inicial $ \\psi (0) $ e a matriz de intensidade $ Q (t) $ permite variar com o tempo. No caso mais simples de uma matriz $ Q $ constante, este é um sistema simples de coeficiente constante de EDOs lineares com coeficientes $ Q ^ T $.\n",
    "\n",
    "Se existir um equilíbrio estacionário, observe que $ \\dot {ψ} (t) = 0 $ e a solução estacionária $ ψ ^ {*} $ precisa atender\n",
    "\n",
    "$$\n",
    "0 = Q^T ψ^{*}\n",
    "$$\n",
    "\n",
    "Observe que este é do formato $ 0 ψ ^ {*} = Q ^ T ψ ^ {*} $ e, portanto, é equivalente a encontrar o vetor próprio associado ao vetor $ \\lambda = 0 $ eigenvalue de $ Q ^ T $.\n",
    "\n",
    "Com o nosso exemplo, podemos calcular todos os autovalores e autovetores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eigen{Float64,Float64,Array{Float64,2},Array{Float64,1}}\n",
       "eigenvalues:\n",
       "6-element Array{Float64,1}:\n",
       " -0.3732050807568874  \n",
       " -0.29999999999999993 \n",
       " -0.19999999999999998 \n",
       " -0.09999999999999995 \n",
       " -0.026794919243112274\n",
       "  0.0                 \n",
       "eigenvectors:\n",
       "6×6 Array{Float64,2}:\n",
       " -0.149429  -0.288675   0.408248   0.5          -0.557678  0.408248\n",
       "  0.408248   0.57735   -0.408248   1.38778e-16  -0.408248  0.408248\n",
       " -0.557678  -0.288675  -0.408248  -0.5          -0.149429  0.408248\n",
       "  0.557678  -0.288675   0.408248  -0.5           0.149429  0.408248\n",
       " -0.408248   0.57735    0.408248   7.63278e-16   0.408248  0.408248\n",
       "  0.149429  -0.288675  -0.408248   0.5           0.557678  0.408248"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "λ, vecs = eigen(Array(Q'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, há um valor próprio $ \\lambda = 0 $, que está associado à última coluna no vetor próprio. Para transformar isso em uma probabilidade, precisamos normalizá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Float64,1}:\n",
       " 0.16666666666666657\n",
       " 0.16666666666666657\n",
       " 0.1666666666666667 \n",
       " 0.16666666666666682\n",
       " 0.16666666666666685\n",
       " 0.16666666666666663"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vecs[:,N] ./ sum(vecs[:,N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensões múltiplas\n",
    "\n",
    "Um caso frequente em modelos discretizados é lidar com cadeias de Markov com múltiplas dimensões \"espaciais\" (por exemplo, riqueza e renda).\n",
    "\n",
    "Após discretizar um processo para criar uma cadeia de Markov, você sempre pode usar o produto cartesiano do conjunto de estados para\n",
    "enumerar como uma única variável de estado.\n",
    "\n",
    "Para ver isso, considere os estados $ i $ e $ j $ governados por geradores infinitesimais $ Q $ e $ A $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×8 Array{Float64,2}:\n",
       " -0.2   0.1   0.0   0.0   0.1   0.0   0.0   0.0\n",
       "  0.1  -0.3   0.1   0.0   0.0   0.1   0.0   0.0\n",
       "  0.0   0.1  -0.3   0.1   0.0   0.0   0.1   0.0\n",
       "  0.0   0.0   0.1  -0.2   0.0   0.0   0.0   0.1\n",
       "  0.2   0.0   0.0   0.0  -0.3   0.1   0.0   0.0\n",
       "  0.0   0.2   0.0   0.0   0.1  -0.4   0.1   0.0\n",
       "  0.0   0.0   0.2   0.0   0.0   0.1  -0.4   0.1\n",
       "  0.0   0.0   0.0   0.2   0.0   0.0   0.1  -0.3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function markov_chain_product(Q, A)\n",
    "    M = size(Q, 1)\n",
    "    N = size(A, 1)\n",
    "    Q = sparse(Q)\n",
    "    Qs = blockdiag(fill(Q, N)...)  # cria blocos diagonais de cada operador\n",
    "    As = kron(A, sparse(I(M)))\n",
    "    return As + Qs\n",
    "end\n",
    "\n",
    "α = 0.1\n",
    "N = 4\n",
    "Q = Tridiagonal(fill(α, N-1), [-α; fill(-2α, N-2); -α], fill(α, N-1))\n",
    "A = sparse([-0.1 0.1\n",
    "    0.2 -0.2])\n",
    "M = size(A,1)\n",
    "L = markov_chain_product(Q, A)\n",
    "L |> Matrix  # exibir como uma matriz densa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso fornece a cadeia de markov combinada para o processo $ (i, j) $. Para ver o padrão de escarsidade,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip6300\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6300)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6301\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip6300)\" points=\"\n",
       "393.14,1487.47 1833.37,1487.47 1833.37,47.2441 393.14,47.2441 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6302\">\n",
       "    <rect x=\"393\" y=\"47\" width=\"1441\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,1487.47 1833.37,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,47.2441 393.14,1487.47 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,1487.47 393.14,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  598.887,1487.47 598.887,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  804.634,1487.47 804.634,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1010.38,1487.47 1010.38,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1216.13,1487.47 1216.13,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1421.88,1487.47 1421.88,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1627.62,1487.47 1627.62,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1833.37,1487.47 1833.37,1465.87 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,47.2441 414.743,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,252.991 414.743,252.991 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,458.739 414.743,458.739 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,664.486 414.743,664.486 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,870.233 414.743,870.233 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,1075.98 414.743,1075.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,1281.73 414.743,1281.73 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  393.14,1487.47 414.743,1487.47 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 393.14, 1541.47)\" x=\"393.14\" y=\"1541.47\">1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 598.887, 1541.47)\" x=\"598.887\" y=\"1541.47\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 804.634, 1541.47)\" x=\"804.634\" y=\"1541.47\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1010.38, 1541.47)\" x=\"1010.38\" y=\"1541.47\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1216.13, 1541.47)\" x=\"1216.13\" y=\"1541.47\">5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1421.88, 1541.47)\" x=\"1421.88\" y=\"1541.47\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1627.62, 1541.47)\" x=\"1627.62\" y=\"1541.47\">7</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1833.37, 1541.47)\" x=\"1833.37\" y=\"1541.47\">8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 64.7441)\" x=\"369.14\" y=\"64.7441\">1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 270.491)\" x=\"369.14\" y=\"270.491\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 476.239)\" x=\"369.14\" y=\"476.239\">3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 681.986)\" x=\"369.14\" y=\"681.986\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 887.733)\" x=\"369.14\" y=\"887.733\">5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 1093.48)\" x=\"369.14\" y=\"1093.48\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 1299.23)\" x=\"369.14\" y=\"1299.23\">7</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 369.14, 1504.97)\" x=\"369.14\" y=\"1504.97\">8</text>\n",
       "</g>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#781c6d; stroke:none; fill-opacity:1\" cx=\"393.14\" cy=\"47.2441\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"393.14\" cy=\"252.991\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fcfea4; stroke:none; fill-opacity:1\" cx=\"393.14\" cy=\"870.233\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"598.887\" cy=\"47.2441\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#33095d; stroke:none; fill-opacity:1\" cx=\"598.887\" cy=\"252.991\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"598.887\" cy=\"458.739\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fcfea4; stroke:none; fill-opacity:1\" cx=\"598.887\" cy=\"1075.98\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"804.634\" cy=\"252.991\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#33095d; stroke:none; fill-opacity:1\" cx=\"804.634\" cy=\"458.739\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"804.634\" cy=\"664.486\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fcfea4; stroke:none; fill-opacity:1\" cx=\"804.634\" cy=\"1281.73\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1010.38\" cy=\"458.739\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#781c6d; stroke:none; fill-opacity:1\" cx=\"1010.38\" cy=\"664.486\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fcfea4; stroke:none; fill-opacity:1\" cx=\"1010.38\" cy=\"1487.47\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1216.13\" cy=\"47.2441\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#33095d; stroke:none; fill-opacity:1\" cx=\"1216.13\" cy=\"870.233\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1216.13\" cy=\"1075.98\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1421.88\" cy=\"252.991\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1421.88\" cy=\"870.233\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#000003; stroke:none; fill-opacity:1\" cx=\"1421.88\" cy=\"1075.98\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1421.88\" cy=\"1281.73\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1627.62\" cy=\"458.739\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1627.62\" cy=\"1075.98\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#000003; stroke:none; fill-opacity:1\" cx=\"1627.62\" cy=\"1281.73\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1627.62\" cy=\"1487.47\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1833.37\" cy=\"664.486\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#fbb419; stroke:none; fill-opacity:1\" cx=\"1833.37\" cy=\"1281.73\" r=\"36\"/>\n",
       "<circle clip-path=\"url(#clip6302)\" style=\"fill:#33095d; stroke:none; fill-opacity:1\" cx=\"1833.37\" cy=\"1487.47\" r=\"36\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip6303\">\n",
       "    <rect x=\"1881\" y=\"47\" width=\"73\" height=\"1441\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<g clip-path=\"url(#clip6303)\">\n",
       "<image width=\"72\" height=\"1440\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAEgAAAWgCAYAAAD9wgUPAAAMT0lEQVR4nO3dwY3sRhAFQY5Q/lsh\n",
       "L6XfLQtUeSQPERYsEg8kmpyZ/f17/r4P/+uvt/+ArxMoCBQECgKFOffft/+GT7OgIFAQKAgUBApz\n",
       "3cVWFhQECgIFgcLc4yK9saAgUBAoCBQECo4awYKCQEGgIFAQKLiLBQsKAgWBgkDBRTpYUBAoCBQE\n",
       "CgIFr32CBQWBgkBBoOCoESwoCBQECgIFgYK7WLCgIFAQKAgUBArzeGC2sqAgUBAoCBRcpIMFBYGC\n",
       "QEGgIFCYxwOzlQUFgYJAQaAgUHAWCxYUBAoCBYGCi3SwoCBQECgIFAQK85x/3v4bPs2CgkBBoCBQ\n",
       "8FYjWFAQKAgUBAoCBQ/MggUFgYJAQaAgUHAXCxYUBAoCBYHC/O6ft/+GT7OgIFAQKAgUBArzHHex\n",
       "jQUFgYJAQaAgUJifu9jKgoJAQaAgUHDUCBYUBAoCBYGCQGEer31WFhQECgIFgYLnQcGCgkBBoCBQ\n",
       "ECh4YBYsKAgUBAoCBYGCs1iwoCBQECgIFBw1ggUFgYJAQaAgUJjfOW//DZ9mQUGgIFAQKAgUnMWC\n",
       "BQWBgkBBoOAiHSwoCBQECgIFgYJ388GCgkBBoCBQmMdbjZUFBYGCQEGgIFBw1AgWFAQKAgWBgkDB\n",
       "a59gQUGgIFAQKLhIBwsKAgWBgkBBoODLLMGCgkBBoCBQECj48EKwoCBQECgIFDwwCxYUBAoCBYGC\n",
       "QMFRI1hQECgIFAQKLtLBgoJAQaAgUBAoeDcfLCgIFAQKAgWBgtc+wYKCQEGgIFDwwCxYUBAoCBQE\n",
       "CgIFd7FgQUGgIFAQKAgU3MWCBQWBgkBBoDDPuW//DZ9mQUGgIFAQKAgU5rmOGhsLCgIFgYJAwfOg\n",
       "YEFBoCBQECgIFDwwCxYUBAoCBYGCQMFZLFhQECgIFAQKLtLBgoJAQaAgUBAoeGAWLCgIFAQKAgWB\n",
       "grNYsKAgUBAoCBTmcY1eWVAQKAgUBAoCBXexYEFBoCBQECiMLxzuLCgIFAQKAgWBgqNGsKAgUBAo\n",
       "CBQECu5iwYKCQEGgIFBwkQ4WFAQKAgWBgkBhHt9lWVlQECgIFAQKAoW55/f23/BpFhQECgIFgYIH\n",
       "ZsGCgkBBoCBQECjM46ixsqAgUBAoCBTmXhfpjQUFgYJAQaAgUHDUCBYUBAoCBYGCQMFdLFhQECgI\n",
       "FAQKHpgFCwoCBYGCQEGg4KgRLCgIFAQKAgWBwjxHo406QaAgUBAoeGAWLCgIFAQKAgWBggdmwYKC\n",
       "QEGgIFDw4ybBgoJAQaAgUBAozHM12qgTBAoCBYGCQMFZLFhQECgIFAQKLtLBgoJAQaAgUBAo+Bhw\n",
       "UCcIFAQKAgWBgs9JBwsKAgWBgkDBx4CDBQWBgkBBoCBQmOuB2UqdIFAQKAgUPA8KFhQECgIFgYJA\n",
       "wQOzYEFBoCBQECgIFDwwC+oEgYJAQaDggVmwoCBQECgIFAQKvpIZLCgIFAQKAgWBwly/YbZSJwgU\n",
       "BAoCBe/mgwUFgYJAQaAgUPDALFhQECgIFAQK3s0HCwoCBYGCQEGg4GPAQZ0gUBAoCBQECs5iwYKC\n",
       "QEGgIFDwViNYUBAoCBQECgIFR41gQUGgIFAQKAgUvPYJ6gSBgkBBoOCoESwoCBQECgIFgYLXPsGC\n",
       "gkBBoCBQcNQIFhQECgIFgYJAwVuNoE4QKAgUBAoCBWexYEFBoCBQECi4SAcLCgIFgYJAQaDgLhYs\n",
       "KAgUBAoCBYGCT5gFCwoCBYGCQGGOf5+1UicIFAQKAgWBggdmwYKCQEGgIFDwPChYUBAoCBQECgIF\n",
       "R41gQUGgIFAQKAgU3MWCBQWBgkBBoOAiHSwoCBQECgIFgYK7WLCgIFAQKAgUBApz3MVWFhQECgIF\n",
       "gYKjRrCgIFAQKAgUBAruYsGCgkBBoCBQcJEOFhQECgIFgYJAwV0sWFAQKAgUBAoCBXexYEFBoCBQ\n",
       "ECj4AFWwoCBQECgIFAQKjhrBgoJAQaAgUBAouIsFCwoCBYGCQMF/ZgnqBIGCQEGgIFBw1AgWFAQK\n",
       "AgWBgnfzwYKCQEGgIFAQKDhqBAsKAgWBgkBBoOAsFiwoCBQECgIFR41gQUGgIFAQKAgU3MWCBQWB\n",
       "gkBBoCBQ8MAsWFAQKAgUBApzHxfpjQUFgYJAQaAgUHDUCBYUBAoCBYGCtxrBgoJAQaAgUBAozLlv\n",
       "/wnfZkFBoCBQECgIFJzFggUFgYJAQaDgrUawoCBQECgIFAQKc3zCbGVBQaAgUBAoCBQ8MAsWFAQK\n",
       "AgWBggdmwYKCQEGgIFAQKDhqBAsKAgWBgkBhztt/wcdZUBAoCBQECgIFR41gQUGgIFAQKAgUvPYJ\n",
       "FhQECgIFgYIfmgwWFAQKAgWBgkDBUSNYUBAoCBQECgIFv2EWLCgIFAQKAgUPzIIFBYGCQEGgIFDw\n",
       "CbNgQUGgIFAQKPgyS7CgIFAQKAgUBAqOGsGCgkBBoCBQECg4iwULCgIFgYJAwVEjWFAQKAgUBAoC\n",
       "BV9mCRYUBAoCBYGCQGF8l2VnQUGgIFAQKDhqBAsKAgWBgkBBoOCoESwoCBQECgIFR41gQUGgIFAQ\n",
       "KAgUHDWCBQWBgkBBoCBQcBYLFhQECgIFgYJfAw4WFAQKAgWBgkDBzyUHCwoCBYGCQEGg4CwWLCgI\n",
       "FAQKAoU5jhorCwoCBYGCQEGgMNdRY2VBQaAgUBAo+ABVsKAgUBAoCBQECr7MEiwoCBQECgIFgYJ3\n",
       "88GCgkBBoCBQ8G4+WFAQKAgUBAoCBe/mgwUFgYJAQaAgUPCvjIMFBYGCQEGg4BNmwYKCQEGgIFAQ\n",
       "KHhgFiwoCBQECgIFz4OCBQWBgkBBoCBQcNQIFhQECgIFgYJAweekgwUFgYJAQaDgG4fBgoJAQaAg\n",
       "UBAo+PWXYEFBoCBQECgIFJzFggUFgYJAQaDgIh0sKAgUBAoCBYGCf2UcLCgIFAQKAgVHjWBBQaAg\n",
       "UBAoCBS8mw8WFAQKAgWBgkDBWSxYUBAoCBQECi7SwYKCQEGgIFAQKHhgFiwoCBQECgIFgYKzWLCg\n",
       "IFAQKAgU/FxysKAgUBAoCBQECn4uOVhQECgIFAQKngcFCwoCBYGCQEGg4N18sKAgUBAoCBQECs5i\n",
       "wYKCQEGgIFCY+7hKbywoCBQECgIFgYKjRrCgIFAQKAgUBApe+wQLCgIFgYJAwVEjWFAQKAgUBAoC\n",
       "BUeNYEFBoCBQECg4agQLCgIFgYJAQaDge/PBgoJAQaAgUBAozPE56ZUFBYGCQEGg4KgRLCgIFAQK\n",
       "AgWBgqNGsKAgUBAoCBQECn70P1hQECgIFAQKcz0xW1lQECgIFAQKAgVHjWBBQaAgUBAo+DJLsKAg\n",
       "UBAoCBQECn4uOVhQECgIFAQKAgVnsWBBQaAgUBAo+BhwsKAgUBAoCBQECh6YBQsKAgWBgkBBoOAs\n",
       "FiwoCBQECgIFF+lgQUGgIFAQKAgU5vhK5sqCgkBBoCBQ8FYjWFAQKAgUBAoCBQ/MggUFgYJAQaAg\n",
       "UHAXCxYUBAoCBYGCi3SwoCBQECgIFAQKcx8/NbmxoCBQECgIFAQKzmLBgoJAQaAgUJjzc9TYWFAQ\n",
       "KAgUBAoChTkemK0sKAgUBAoCBRfpYEFBoCBQECgIFLybDxYUBAoCBYGCQGHOz7v5jQUFgYJAQaDg\n",
       "gVmwoCBQECgIFAQK7mLBgoJAQaAgUBAoeO0TLCgIFAQKAoU5z5+3/4ZPs6AgUBAoCBQECh6YBQsK\n",
       "AgWBgkBhrqPGyoKCQEGgIFAQKDhqBAsKAgWBgkBBoOAuFiwoCBQECgIFD8yCBQWBgkBBoCBQcNQI\n",
       "FhQECgIFgYJAwVksWFAQKAgUBAq+cRgsKAgUBAoCBYHCnOsutrGgIFAQKAgUHDWCBQWBgkBBoCBQ\n",
       "mOuosbKgIFAQKAgUBArOYsGCgkBBoCBQ8AGqYEFBoCBQECgIFLybDxYUBAoCBYGCQMEDs2BBQaAg\n",
       "UBAoeDcfLCgIFAQKAgWBgtc+wYKCQEGgIFBw1AgWFAQKAgWBgkDBW41gQUGgIFAQKAgUnMWCBQWB\n",
       "gkBBoOCtRrCgIFAQKAgUBAqOGsGCgkBBoCBQECh47RMsKAgUBAoChbnXA7ONBQWBgkBBoCBQcNQI\n",
       "FhQECgIFgcI89779N3yaBQWBgkBBoCBQmMdRY2VBQaAgUBAoCBR8wixYUBAoCBQECo4awYKCQEGg\n",
       "IFAQKHg3HywoCBQECgIFgcI8HpitLCgIFAQKAgVHjWBBQaAgUBAoCBS89gkWFAQKAgWBwn8v2/BP\n",
       "X8iooQAAAABJRU5ErkJggg==\n",
       "\" transform=\"translate(1881, 47)\"/>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 1501.13)\" x=\"1989.37\" y=\"1501.13\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2017.48, 1501.13)\" x=\"2017.48\" y=\"1501.13\">0.4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 1261.09)\" x=\"1989.37\" y=\"1261.09\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2017.48, 1261.09)\" x=\"2017.48\" y=\"1261.09\">0.3</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 1021.05)\" x=\"1989.37\" y=\"1021.05\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2017.48, 1021.05)\" x=\"2017.48\" y=\"1021.05\">0.2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 781.011)\" x=\"1989.37\" y=\"781.011\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 2017.48, 781.011)\" x=\"2017.48\" y=\"781.011\">0.1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 540.972)\" x=\"1989.37\" y=\"540.972\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 300.934)\" x=\"1989.37\" y=\"300.934\">0.1</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip6300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 1989.37, 60.8953)\" x=\"1989.37\" y=\"60.8953\">0.2</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip6300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1953.37,1487.47 1953.37,1487.47 1977.37,1487.47 1953.37,1487.47 1953.37,1247.44 1977.37,1247.44 1953.37,1247.44 1953.37,1007.4 1977.37,1007.4 1953.37,1007.4 \n",
       "  1953.37,767.359 1977.37,767.359 1953.37,767.359 1953.37,527.321 1977.37,527.321 1953.37,527.321 1953.37,287.283 1977.37,287.283 1953.37,287.283 1953.37,47.2441 \n",
       "  1977.37,47.2441 1953.37,47.2441 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "spy(L, markersize = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular uma avaliação dinâmica simples, considere se o retorno do estado $ (i, j) $ é $ r_ {ij} = i + 2j $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 3.0\n",
       " 4.0\n",
       " 5.0\n",
       " 6.0\n",
       " 5.0\n",
       " 6.0\n",
       " 7.0\n",
       " 8.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = [i + 2.0j for i in 1:N, j in 1:M]\n",
    "r = vec(r)  # vetorizá-lo desde qu esteja empilhado na mesma ordem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolvendo a equação $ \\rho v = r + L v $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float64,2}:\n",
       "  87.8992   93.6134\n",
       "  96.1345  101.849 \n",
       " 106.723   112.437 \n",
       " 114.958   120.672 "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ρ = 0.05\n",
    "v = (ρ * I - L) \\ r\n",
    "reshape(v, N, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `reshape` ajuda a reorganizá-lo novamente para ser bidimensional.\n",
    "\n",
    "Para encontrar a distribuição estacionária, calculamos o valor próprio e escolhemos o vetor próprio associado a $ \\lambda = 0 $. Nesse caso, podemos verificar se é o último."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Float64,1}:\n",
       " 0.16666666666666677\n",
       " 0.1666666666666665 \n",
       " 0.16666666666666682\n",
       " 0.16666666666666666\n",
       " 0.08333333333333325\n",
       " 0.08333333333333345\n",
       " 0.0833333333333333 \n",
       " 0.08333333333333334"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_eig = eigen(Matrix(L'))\n",
    "@assert norm(L_eig.values[end]) < 1E-10\n",
    "\n",
    "ψ = L_eig.vectors[:,end]\n",
    "ψ = ψ / sum(ψ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remodelando isso para ser bidimensional, se for útil para visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×2 Array{Float64,2}:\n",
       " 0.166667  0.0833333\n",
       " 0.166667  0.0833333\n",
       " 0.166667  0.0833333\n",
       " 0.166667  0.0833333"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape(ψ, N, size(A,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Irredutibulidade\n",
    "\n",
    "Como nas cadeias discretas de Markov, uma questão-chave é se os CTMCs são redutíveis, ou seja, os estados se comunicam. O problema é isomórfico para determinar se o gráfico direcionado da cadeia de Markov está [fortemente conectado](https://en.wikipedia.org/wiki/Strongly_connected_component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Tridiagonal{Float64,Array{Float64,1}}:\n",
       " -0.1   0.1    ⋅     ⋅     ⋅     ⋅ \n",
       "  0.1  -0.2   0.1    ⋅     ⋅     ⋅ \n",
       "   ⋅    0.1  -0.2   0.1    ⋅     ⋅ \n",
       "   ⋅     ⋅    0.1  -0.2   0.1    ⋅ \n",
       "   ⋅     ⋅     ⋅    0.1  -0.2   0.1\n",
       "   ⋅     ⋅     ⋅     ⋅    0.1  -0.1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LightGraphs\n",
    "α = 0.1\n",
    "N = 6\n",
    "Q = Tridiagonal(fill(α, N-1), [-α; fill(-2α, N-2); -α], fill(α, N-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar se é possível alternar entre todos os estados em um número finito de etapas com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_strongly_connected(Q_graph) = true\n"
     ]
    }
   ],
   "source": [
    "Q_graph = DiGraph(Q)\n",
    "@show is_strongly_connected(Q_graph);  # i.e. pode seguir arestas direcionais para chegar a todos os estados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como alternativa, como um exemplo de uma cadeia Markov redutível em que os estados $ 1 $ e $ 2 $ não podem pular para o estado $ 3 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_strongly_connected(Q_graph) = false\n"
     ]
    }
   ],
   "source": [
    "Q = [-0.2 0.2 0\n",
    "    0.2 -0.2 0\n",
    "    0.2 0.6 -0.2]\n",
    "Q_graph = DiGraph(Q)\n",
    "@show is_strongly_connected(Q_graph);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrizes em Faixas\n",
    "\n",
    "Uma matriz tridiagonal possui 3 diagonais diferentes de zero. A diagonal principal, a primeira sub-diagonal (isto é, abaixo da diagonal principal) e também a primeira super-diagonal (isto é, acima da diagonal principal).\n",
    "\n",
    "Este é um caso especial de um tipo mais geral chamado matriz em faixas, em que o número de sub e super-diagonais pode ser maior que 1. A largura total das principais, sub e superdiagonais é chamada de largura de banda. Por exemplo, uma matriz tridiagonal tem uma largura de banda de 3.\n",
    "\n",
    "Uma matriz em faixas $ N \\times N $ com largura de banda $ P $ possui cerca de $ N P $ nonzeros em seu padrão de escassez.\n",
    "\n",
    "Estes podem ser criados diretamente como uma matriz densa com `diagm`. Por exemplo, com uma largura de banda de três e uma diagonal zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Int64,2}:\n",
       " 0  1  0  0\n",
       " 4  0  2  0\n",
       " 0  5  0  3\n",
       " 0  0  6  0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diagm(1 => [1,2,3], -1 => [4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou como uma matriz esparsa,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 SparseMatrixCSC{Int64,Int64} with 6 stored entries:\n",
       "  [2, 1]  =  4\n",
       "  [1, 2]  =  1\n",
       "  [3, 2]  =  5\n",
       "  [2, 3]  =  2\n",
       "  [4, 3]  =  6\n",
       "  [3, 4]  =  3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spdiagm(1 => [1,2,3], -1 => [4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, usando diretamente [BandedMatrices.jl](https://github.com/JuliaMatrices/BandedMatrices.jl):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 BandedMatrix{Int64,Array{Int64,2},Base.OneTo{Int64}}:\n",
       " 0  1  ⋅  ⋅\n",
       " 4  0  2  ⋅\n",
       " ⋅  5  0  3\n",
       " ⋅  ⋅  6  0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BandedMatrices\n",
    "BandedMatrix(1 => [1,2,3], -1 => [4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há também uma função de conveniência para gerar matrizes aleatórias em faixas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×7 BandedMatrix{Float64,Array{Float64,2},Base.OneTo{Int64}}:\n",
       " 0.109687  0.719595   ⋅         ⋅         ⋅         ⋅         ⋅      \n",
       " 0.197615  0.441325  0.486003   ⋅         ⋅         ⋅         ⋅      \n",
       " 0.909192  0.999804  0.438857  0.424792   ⋅         ⋅         ⋅      \n",
       " 0.365279  0.231345  0.449552  0.754709  0.155209   ⋅         ⋅      \n",
       "  ⋅        0.32635   0.374328  0.815217  0.41038   0.13815    ⋅      \n",
       "  ⋅         ⋅        0.386271  0.770824  0.976365  0.816799  0.841751\n",
       "  ⋅         ⋅         ⋅        0.624999  0.177116  0.135212  0.158908"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = brand(7, 7, 3, 1)  # matriz 7x7, 3 subdiagonais, 1 subdiagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E, é claro, algoritmos especializados serão usados para explorar a estrutura ao resolver sistemas lineares. Em particular, a complexidade está relacionada ao $ O (N P_L P_U) $ para larguras de banda superior e inferior $ P $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factorize(Symmetric(A)) |> typeof = LDLt{Float64,Symmetric{Float64,BandedMatrix{Float64,Array{Float64,2},Base.OneTo{Int64}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7-element Array{Float64,1}:\n",
       "  -2.8366241417063507\n",
       "   1.794969986790177 \n",
       "   1.0559189288823672\n",
       "   1.261653262303674 \n",
       "   1.157700843466614 \n",
       " -15.915612135771756 \n",
       "  12.632869787809963 "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show factorize(Symmetric(A)) |> typeof\n",
    "A \\ rand(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo de fatoração usa uma decomposição LU especializada para matrizes em faixas.\n",
    "\n",
    "\n",
    "<a id='implementation-numerics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalhes da Implementação e Performance\n",
    "\n",
    "Lembre-se da famosa citação de Knuth: “97% das vezes: a otimização prematura é a raiz de todo mal. No entanto, não devemos perder nossas oportunidades nesses 3% críticos ”. O exemplo mais comum de otimização prematura é tentar usar seu próprio modelo mental de compilador enquanto escreve seu código, preocupado com a eficiência do código e (geralmente incorretamente) adivinhar o compilador.\n",
    "\n",
    "Concretamente, as lições desta seção são:\n",
    "\n",
    "\n",
    "1. Não se preocupe em otimizar seu código, a menos que você precise. A clareza do código é sua preocupação de primeira ordem.\n",
    "2. Se você usar os pacotes de outras pessoas, eles poderão se preocupar com o desempenho e você não precisará.\n",
    "3. Se você precisa absolutamente desses 3% críticos, sua intuição sobre o desempenho geralmente está errada em CPUs e GPUs modernas, portanto, deixe o compilador fazer seu trabalho.\n",
    "4. Benchmarking (por exemplo, `@ btime`) e [profiling](https://docs.julialang.org/en/v1/manual/profile/) são as ferramentas para descobrir gargalos de desempenho. Se 99% do tempo de computação é gasto em uma função pequena, então não faz sentido otimizar mais nada.\n",
    "5. Se você fizer um benchmark para mostrar que uma parte específica do código é um problema e não encontrar outra biblioteca que faça um trabalho melhor, poderá se preocupar com o desempenho.\n",
    "\n",
    "\n",
    "Você raramente chegará ao passo 3, e muito menos ao passo 5.\n",
    "\n",
    "No entanto, há também um corolário: \"não pessimize prematuramente\". Ou seja, não faça escolhas que levem a um desempenho ruim sem qualquer troca na clareza de código aprimorada. Por exemplo, escrevendo seus próprios algoritmos quando existe um algoritmo de alto desempenho em um pacote ou na própria Julia, ou preguiçosamente tornando uma matriz densa e descuidando descuidadamente sua estrutura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dificuldade de implementação\n",
    "\n",
    "Às vezes, a análise numérica se refere ao nível mais baixo de código para operações básicas (por exemplo, um produto escalar, produto matriz-matriz, convoluções) como `kernels`.\n",
    "\n",
    "Esse tipo de código é difícil de escrever e o desempenho depende das características do hardware subjacente, como o [conjunto de instruções](https://en.wikipedia.org/wiki/Instruction_set_architecture) disponível na CPU específica, o tamanho de o [cache da CPU](https://en.wikipedia.org/wiki/CPU_cache) e o layout das matrizes na memória.\n",
    "\n",
    "Normalmente, essas operações são gravadas em uma biblioteca intitulada [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms), organizada em diferentes níveis. Os níveis correspondem aproximadamente à ordem computacional das operações: o nível 1 do BLAS é operações de $ O (N) $, como produtos lineares, o nível 2 é operações de $ O (N ^ 2) $, como produtos vetoriais matriciais e o nível 3 são $ O (N ^ 3) $, como produtos matriciais gerais.\n",
    "\n",
    "Um exemplo de uma biblioteca BLAS é o [OpenBLAS](https://github.com/xianyi/OpenBLAS) usado por padrão em Julia ou o [Intel MKL](https://en.wikipedia.org/wiki/Math_Kernel_Library) usado no Matlab (e Julia se o pacote `MKL.jl` estiver instalado).\n",
    "\n",
    "No topo do BLAS estão as operações [LAPACK](https://en.wikipedia.org/wiki/LAPACK), que são kernels de nível superior, como fatorações de matriz e algoritmos de autovalor, e geralmente estão nas mesmas bibliotecas (por exemplo, MKL funcionalidade BLAS e LAPACK).\n",
    "\n",
    "Os detalhes desses pacotes não são especialmente relevantes, mas se você estiver falando sobre desempenho, as pessoas inevitavelmente começarão a discutir esses diferentes pacotes e kernels. Há algumas coisas importantes a serem lembradas:\n",
    "\n",
    "1. Deixe os kernels de escrita para os especialistas. Mesmo algoritmos de som simples podem ser muito complicados para obter alto desempenho.\n",
    "2. Sua intuição sobre o desempenho do código provavelmente estará errada. Se você usa bibliotecas de alta qualidade em vez de escrever seus próprios kernels, não precisa usar sua intuição.\n",
    "3. Não se distraia com o jargão ou as siglas acima se estiver lendo sobre desempenho.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordenação de linhas e colunas principais\n",
    "\n",
    "Há um problema de desempenho prático que pode influenciar seu código. Como a memória em uma CPU é linear, as matrizes densas precisam ser armazenadas pelas colunas de empilhamento (chamadas de [ordem principal da coluna](https://en.wikipedia.org/wiki/Row-_and_column-major_order)) ou linhas.\n",
    "\n",
    "A razão pela qual isso importa é que os compiladores podem gerar melhor desempenho se trabalharem em blocos contíguos de memória, e isso se torna especialmente importante com matrizes grandes devido à interação com o cache da CPU. Escolher a ordem errada quando não houver benefício na clareza do código é um exemplo de pessimização prematura. A diferença de desempenho pode ser de magnitude em alguns casos, e nada em outros.\n",
    "\n",
    "Uma opção é usar as funções que permitem ao compilador escolher a maneira mais eficiente de atravessar a memória. Se você precisar escolher a ordem de loop você mesmo, poderá experimentar a troca se passa por colunas ou linhas primeiro. Outras vezes, deixe Julia decidir, ou seja, `enumerate` e` eachindex` escolherão a abordagem correta.\n",
    "\n",
    "Julia, Fortran e Matlab usam a ordem principal da coluna, enquanto C / C ++ e Python usam a ordem principal da linha. Isso significa que, se você encontrar um algoritmo escrito para C / C ++ / Python, às vezes precisará fazer pequenas alterações se o desempenho for um problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digressão em alocações e operações no local\n",
    "\n",
    "Embora em geral não tenhamos considerado a otimização do código de desempenho (e focado na escolha de\n",
    "algoritmos), quando matrizes e vetores se tornam grandes, precisamos ter mais cuidado.\n",
    "\n",
    "O mais importante a evitar são alocações em excesso, que geralmente ocorrem devido ao uso de\n",
    "vetores e matrizes temporários quando não são necessários. Às vezes, esses valores temporários extras\n",
    "pode causar enormes prejuízos no desempenho.\n",
    "\n",
    "No entanto, recomenda-se cautela, pois alocações em excesso nunca são relevantes para valores escalares e às vezes podem criar código mais rápido para matrizes/vetores menores, pois pode levar a uma melhor [localidade do cache](https://en.wikipedia.org/wiki/Locality_of_reference).\n",
    "\n",
    "Para ver isso, uma ferramenta conveniente é o benchmarking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  507.394 ns (1 allocation: 896 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×10 Array{Float64,2}:\n",
       " 2.38445  4.30622  4.15903  3.43694  …  3.82611  3.48099  4.66099  4.35607\n",
       " 2.07897  3.28677  2.97151  2.58452     2.2157   2.01165  3.32382  2.21331\n",
       " 2.54002  3.44218  3.4829   2.87813     2.96005  2.66545  3.65305  3.26997\n",
       " 2.40094  4.18545  3.74416  3.26441     3.51722  3.01934  4.31747  3.32135\n",
       " 2.55308  4.34568  4.47826  3.4746      3.62313  2.88039  4.73586  3.59672\n",
       " 3.18104  4.39641  4.05575  3.64642  …  3.61473  3.48923  4.58765  4.03799\n",
       " 1.83945  2.78571  2.94542  2.3359      2.78569  2.30381  2.96308  2.74603\n",
       " 3.01062  4.81368  4.80904  4.09877     3.79633  3.59909  5.48354  4.64111\n",
       " 2.70346  3.68773  4.00306  3.2046      3.50494  2.952    3.97194  3.44871\n",
       " 3.13711  4.92273  4.50483  3.90205     3.67632  3.14191  5.35983  3.91963"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "A = rand(10,10)\n",
    "B = rand(10,10)\n",
    "C = similar(A)\n",
    "function f!(C, A, B)\n",
    "    D = A*B\n",
    "    C .= D .+ 1\n",
    "end\n",
    "@btime f!($C, $A, $B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O `!` no `f!` É uma maneira informal de dizer que a função está em mutação e os primeiros argumentos (`C` aqui)\n",
    "é por convenção os valores modificados.\n",
    "\n",
    "Na função `f!`, Observe que o `D` é uma variável temporária que é criada e modificada posteriormente. Mas observe que desde\n",
    "`C` é modificado diretamente, não há necessidade de criar a matriz temporária` D`.\n",
    "\n",
    "Este é um exemplo de onde uma versão local da multiplicação de matrizes pode ajudar a evitar a alocação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  509.036 ns (1 allocation: 896 bytes)\n",
      "  439.611 ns (0 allocations: 0 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10×10 Array{Float64,2}:\n",
       " 4.17849  3.99982  4.08701  2.9107   …  3.67517  2.94196  2.97447  3.31776\n",
       " 3.16593  2.78189  2.3274   2.18093     2.99242  1.95574  2.22242  2.46963\n",
       " 4.22215  4.28371  4.28939  3.7742      4.09352  2.90929  2.49942  4.3231 \n",
       " 3.31492  3.35675  3.29948  2.42587     3.04878  2.60989  2.24203  2.96472\n",
       " 3.90282  3.59304  3.44081  3.26894     3.4765   2.74166  2.16695  3.87907\n",
       " 3.35249  3.38256  3.12494  2.23225  …  3.10104  2.22678  2.49182  2.56156\n",
       " 5.36237  4.89655  4.94874  4.24799     4.21646  3.44149  3.31918  4.7045 \n",
       " 3.6767   3.77135  3.41933  3.54367     3.32444  2.95376  2.36089  3.53425\n",
       " 3.24527  3.1745   2.74173  2.25294     3.57247  2.48904  2.09367  2.76493\n",
       " 4.59976  4.63393  4.88462  4.04115     3.95369  3.24873  3.08891  4.31279"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f2!(C, A, B)\n",
    "    mul!(C, A, B)  # multiplicação no lugar\n",
    "    C .+= 1\n",
    "end\n",
    "A = rand(10,10)\n",
    "B = rand(10,10)\n",
    "C = similar(A)\n",
    "@btime f!($C, $A, $B)\n",
    "@btime f2!($C, $A, $B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que, na saída do benchmarking, o `f2!` Não está alocado e está usando a variável `C` pré-alocada diretamente.\n",
    "\n",
    "Outro exemplo disso são as soluções para equações lineares, nas quais para grandes soluções você pode pré-chamar e reutilizar o\n",
    "vetor de solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Float64,1}:\n",
       "  0.43707922462467835\n",
       " -0.4255000330850714 \n",
       "  0.9826038617340918 \n",
       " -0.2691960077744889 \n",
       "  0.48136882810093035\n",
       " -0.7545857358302918 \n",
       "  0.6645076917313447 \n",
       "  0.22854831057636865\n",
       " -1.4456879854514966 \n",
       "  1.3427409373482915 "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(10,10)\n",
    "y = rand(10)\n",
    "z = A \\ y  # cria temporário\n",
    "\n",
    "A = factorize(A)  # local exige fatoração\n",
    "x = similar(y)  # pré-alocação\n",
    "ldiv!(x, A, y)  # divisão esquerda no local, usando fatoração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, se você fizer um benchmark com cuidado, verá que isso às vezes é mais lento. Evitar alocações nem sempre é uma boa\n",
    "idéia - e se preocupar com isso antes do benchmarking é a otimização prematura.\n",
    "\n",
    "Há uma variedade de outras versões de funções não alocadas. Por exemplo,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×10 Array{Float64,2}:\n",
       " 0.332025   0.234278  0.70827   0.411295   …  0.327127  0.85295    0.11247   \n",
       " 0.904854   0.827702  0.154587  0.448786      0.178535  0.69811    0.998019  \n",
       " 0.481155   0.218838  0.584614  0.519837      0.946165  0.143201   0.336193  \n",
       " 0.993505   0.947485  0.644861  0.0350973     0.351794  0.802639   0.00477567\n",
       " 0.442824   0.836457  0.308395  0.336602      0.802745  0.0752838  0.0847486 \n",
       " 0.0680403  0.578927  0.137693  0.411517   …  0.315455  0.0293899  0.617513  \n",
       " 0.487702   0.115422  0.95813   0.431378      0.877839  0.111185   0.131022  \n",
       " 0.602005   0.31347   0.276449  0.794457      0.964883  0.474389   0.123424  \n",
       " 0.812738   0.695384  0.810153  0.135141      0.200575  0.486323   0.992133  \n",
       " 0.16448    0.745776  0.957567  0.186042      0.639482  0.155409   0.710451  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(10,10)\n",
    "B = similar(A)\n",
    "\n",
    "transpose!(B, A)  # versão não-alocada de B = transposta(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, uma fonte comum de alocações desnecessárias é a obtenção de fatias ou partes de matrizes. Por exemplo, o seguinte aloca uma nova matriz `B` e copia os valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 0.4267409868807137 \n",
       " 0.4607555356602602 \n",
       " 0.9735329756215609 \n",
       " 0.9120216968454979 \n",
       " 0.17219390913608557"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(5,5)\n",
    "B = A[2,:]  # extrair um vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver essas matrizes diferentes, observe que"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A[2, 1] = 100.0\n",
      "B[1] = 0.4267409868807137\n"
     ]
    }
   ],
   "source": [
    "A[2,1] = 100.0\n",
    "@show A[2,1]\n",
    "@show B[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de alocar uma nova matriz, você pode fazer uma `view` de uma matriz, que fornece um tipo` AbstractArray` apropriado que não aloca nova memória com a matriz `@ view`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A[2, 1] = 100.0\n",
      "B[1] = 100.0\n"
     ]
    }
   ],
   "source": [
    "A = rand(5,5)\n",
    "B = @view A[2,:]  #  não copia os dados\n",
    "\n",
    "A[2,1] = 100.0\n",
    "@show A[2,1]\n",
    "@show B[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mas, novamente, você encontrará muitas vezes que fazer `@ view` leva a um código mais lento. Em vez disso, faça referência e geralmente confie nela para matrizes grandes e para pedaços de memória contíguos (por exemplo, uma coluna em vez de uma linha)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "Este exercício é para uma prática de escrever rotinas de baixo nível (ou seja, \"kernels\") e esperamos convencê-lo a deixar o código de baixo nível para os especialistas.\n",
    "\n",
    "A fórmula para multiplicação de matrizes é enganosamente simples. Por exemplo, com o produto de matrizes quadradas $ C = A B $ de tamanho $ N \\times N $, o elemento $ i, j $ de $ C $ é:\n",
    "\n",
    "$$\n",
    "C_{ij} = \\sum_{k=1}^N A_{ik} B_{kj}\n",
    "$$\n",
    "\n",
    "Como alternativa, você pode pegar uma linha $ A_ {i ,:} $ e a coluna $ B_ {:, j} $ e usar um produto interno:\n",
    "\n",
    "$$\n",
    "C_{ij} = A_{i,:} \\cdot B_{:,j}\n",
    "$$\n",
    "\n",
    "Observe que o produto interno em um espaço discreto é simplesmente uma soma e tem a mesma complexidade da soma (ou seja, operações $ O (N) $).\n",
    "\n",
    "Para uma matriz densa sem nenhuma estrutura, isso também esclarece por que a complexidade é $ O (N ^ 3) $: é necessário avaliá-la para elementos $ N ^ 2 $ na matriz e fazer $ O (N) $ operação cada vez.\n",
    "\n",
    "Para este exercício, implemente a multiplicação de matrizes e compare o desempenho em algumas permutações.\n",
    "\n",
    "1. Use a função interna em Julia (ou seja, `` C = A * B`` ou, para uma melhor comparação, a versão local `mul! (C, A, B)` que funciona com dados pré-alocados)\n",
    "2. Faça um loop sobre cada $ C_ {ij} $ pela linha primeiro (ou seja, o índice `i`) e use um loop` for` para o produto interno\n",
    "3. Faça um loop sobre cada $ C_ {ij} $ pela coluna primeiro (ou seja, o índice `j`) e use um loop` for` para o produto interno\n",
    "4. Faça o mesmo, mas use o produto `dot 'em vez da soma.\n",
    "5. Escolha sua melhor implementação e, em seguida, para matrizes de alguns tamanhos diferentes `N = 10`,` N = 1000`, etc. e compare a taxa de desempenho de sua melhor implementação com a biblioteca BLAS incorporada.\n",
    "\n",
    "\n",
    "Mais algumas dicas:\n",
    "\n",
    "- Você pode usar apenas matrizes aleatórias, por exemplo `A = margem (N, N)`, etc.\n",
    "- Para todos eles, pré-aloque previamente a matriz $ C $ com `C = similar (A)` ou algo equivalente.\n",
    "- Para comparar o desempenho, coloque seu código em uma função e use a macro `@ btime` para cronometrar.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2a\n",
    "\n",
    "Aqui calcularemos a evolução do pdf de uma cadeia de Markov de tempo discreto, $ \\ psi_t $, dada a condição inicial $ \\psi_0 $.\n",
    "\n",
    "Comece com uma matriz tridiagonal simétrica simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "A = Tridiagonal([fill(0.1, N-2); 0.2], fill(0.8, N), [0.2; fill(0.1, N-2)])\n",
    "A_adjoint = A';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escolha um `T` grande e use a condição inicial $ \\psi_0 = \\begin {bmatrix} 1 & 0 & \\ldots & 0 \\end {bmatrix} $\n",
    "2. Escreva o código para calcular $ \\ psi_t $ para alguns $ T $ iterando o mapa para cada $ t $, ou seja,\n",
    "\n",
    "\n",
    "$$\n",
    "\\psi_ {t + 1} = A '\\psi_t\n",
    "$$\n",
    "\n",
    "3. Qual é a ordem computacional desse cálculo $ \\psi_T $ usando essa abordagem de iteração $ T <N $?\n",
    "4. Qual é a ordem computacional de $ (A ') ^ T = (A \\ldots A) $ e então $ \\psi_T = (A') ^ T \\psi_0 $ para $ T <N $?\n",
    "5. Benchmark calculando $ \\psi_T $ com o cálculo iterativo acima, bem como o $ \\psi_T = (A ') ^ T \\psi_0 $ direto para ver qual é mais rápido. Você pode obter a potência da matriz com apenas `A_adjoint ^ T`, que usa algoritmos especializados mais rapidamente e com mais precisão do que a multiplicação de matriz repetida (mas com a mesma ordem computacional).\n",
    "6. Verifique o mesmo se $ T = 2 N $\n",
    "\n",
    "\n",
    "* Nota: * O algoritmo usado em Julia para obter poderes da matriz depende da estrutura da matriz, como sempre. No caso simétrico, ele pode usar uma composição independente, enquanto que com uma matriz densa geral ele usa [quadrado e escala](https://doi.org/10.1137/090768539)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2b\n",
    "\n",
    "Com a mesma configuração do Exercício 2a, faça uma [autodecomposição](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix) de `A_transposta`. Ou seja, use `eigen` para fatorar o adjacente $ A '= Q \\Lambda Q ^ {- 1} $ onde $ Q $ a matriz de vetores próprios e $ \\Lambda $ a matriz diagonal de valores próprios. Calcule $ Q ^ {- 1} $ a partir dos resultados.\n",
    "\n",
    "Use a matriz fatorada para calcular a sequência de $ \\ psi_t = (A ') ^ t \\ psi_0 $ usando o relacionamento\n",
    "\n",
    "$$\n",
    "\\psi_t = Q \\Lambda ^ t Q ^ {- 1} \\psi_0\n",
    "$$\n",
    "\n",
    "Onde os poderes matriciais das matrizes diagonais são simplesmente os poderes dos elementos de cada elemento.\n",
    "\n",
    "Compare a velocidade do cálculo da sequência de $ \\psi_t $ até `T = 2N` usando este método. Em princípio, a fatoração e o cálculo fácil da potência devem oferecer benefícios em comparação com a simples iteração do mapa, como fizemos no Exercício 2a. Explique por que ele usa ou não a ordem computacional de cada abordagem."
   ]
  }
 ],
 "metadata": {
  "date": 1580349911.1283185,
  "download_nb": 1,
  "download_nb_path": "https://julia.quantecon.org/",
  "filename": "numerical_linear_algebra.rst",
  "filename_with_path": "tools_and_techniques/numerical_linear_algebra",
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  },
  "title": "Numerical Linear Algebra and Factorizations"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
