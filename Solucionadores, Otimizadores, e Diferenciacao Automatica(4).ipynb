{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id='optimization-solver-packages'></a>\n",
    "<div id=\"qe-notebook-header\" style=\"text-align:right;\">\n",
    "        <a href=\"https://quantecon.org/\" title=\"quantecon.org\">\n",
    "                <img style=\"width:250px;display:inline;\" src=\"https://assets.quantecon.org/img/qe-menubar-logo.svg\" alt=\"QuantEcon\">\n",
    "        </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solucionadores, Otimizadores, e Diferenciação Automática"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "- [Solucionadores, Otimizadores, e Diferenciação Automática](#Solucionadores,-Otimizadores,-e-Diferenciação-Automática)  \n",
    "  - [Resumo](#Resumo)  \n",
    "  - [Introdução a Diferenciação Automática](#Introdução-a-Diferenciação-Automática)  \n",
    "  - [Otimização](#Otimização)  \n",
    "  - [Sistema de Equações e Mínimos Quadrados](#Sistema-de-Equações-e-Mínimos-Quadrados)  \n",
    "  - [LeastSquaresOptim.jl](#LeastSquaresOptim.jl)  \n",
    "  - [Notas Adicionais](#Notas-Adicionais)  \n",
    "  - [Exercícios](#Exercícios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Devidamente traduzido, revisado e adaptado do [QuantEcon](https://quantecon.org/) pelos bolsistas CNPq, Pedro Luiz H. Furtado e Jonas Aragão M. Corpes, sob supervisão do Prof. Christiano Penna, do CAEN/UFC.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "Nesta aula, apresentamos algumas das bibliotecas do Julia que consideramos particularmente úteis para trabalhos quantitativos em economia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide-output": true
   },
   "outputs": [],
   "source": [
    "using InstantiateFromURL\n",
    "github_project(\"QuantEcon/quantecon-notebooks-julia\", version = \"0.5.0\")\n",
    "# github_project(\"QuantEcon/quantecon-notebooks-julia\", version = \"0.5.0\", instantiate = true) # uncomment to force package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide-output": true
   },
   "outputs": [],
   "source": [
    "using LinearAlgebra, Statistics\n",
    "using ForwardDiff, Zygote, Optim, JuMP, Ipopt, BlackBoxOptim, Roots, NLsolve, LeastSquaresOptim\n",
    "using Optim: converged, maximum, maximizer, minimizer, iterations #algumas funções extras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução a Diferenciação Automática\n",
    "\n",
    "A promessa de uma programação diferenciável é que podemos avançar para obter derivadas quase arbitrariamente cpmplicadas em\n",
    "programas de computador, em vez de simplesmente pensar nas derivadas das funções matemáticas. A programação diferenciável é a evolução natural da diferenciação automática (DA, às vezes chamada de diferenciação algorítmica).\n",
    "\n",
    "Recuando, existem três maneiras de calcular o gradiente ou o efeito jacobiano:\n",
    "\n",
    "- Derivadas analíticas / Diferenciação simbólica\n",
    "  \n",
    "  - Às vezes, você pode calcular a derivada em caneta e papel e potencialmente simplificar a expressão.\n",
    "  - Com efeito, aplicações repetidas da regra da cadeia, regra do produto etc.\n",
    "  - Às vezes, embora nem sempre, seja a opção mais precisa e rápida, se houver simplificações algébricas.\n",
    "  - Às vezes, a integração simbólica no computador é uma boa solução, se o pacote puder lidar com suas funções. Fazer álgebra manualmente é tedioso e propenso a erros, e às vezes é inestimável.\n",
    "    \n",
    "- Diferenças finitas:  \n",
    "  \n",
    "  - Avalie a função pelo menos $ N $ para obter o gradiente – Jacobianos são ainda piores.  \n",
    "  - $ \\Delta $ Grande é numericamente estável, mas impreciso, $ \\Delta $ muito pequeno, é numericamente instavel, porém mais preciso.\n",
    "  - Evite se puder e use pacotes (por exemplo, [DiffEqDiffTools.jl](https://github.com/JuliaDiffEq/DiffEqDiffTools.jl) ) para obter uma boa escolha do $ \\Delta $  \n",
    "  - Se uma função é $ R^N \\to R $ para um grande $ N $, isso exige avaliações da função $ O(N) $.\n",
    "\n",
    "\n",
    "$$\n",
    "\\partial_{x_i}f(x_1,\\ldots x_N) \\approx \\frac{f(x_1,\\ldots x_i + \\Delta,\\ldots x_N) - f(x_1,\\ldots x_i,\\ldots x_N)}{\\Delta}\n",
    "$$\n",
    "\n",
    "\n",
    "- Diferenciação automática. \n",
    "  \n",
    "  - O mesmo que diferenciação analítica/simbólica, mas onde a **regra da cadeia** é calculada **numericamente** em vez de simbolicamente.\n",
    "  - Assim como com derivadas analíticas, é possível estabelecer regras para derivadas de funções individuais (por exemplo, $ d \\left (sin(x) \\right) $ a $ cos (x) dx $) para derivadas intrínsecas.\n",
    "  \n",
    "A DA possui duas abordagens básicas, que são variações na ordem de avaliação da regra da cadeia: modo reverso e encaminhamento (embora o modo misto seja possível).\n",
    "\n",
    "1. Se uma função é $ R^N \\to R $, **modo reverso** DA pode encontrar o gradiente em $ O(1) $ sweep (onde uma \"varredura\" é a função $ O(1) $ avaliações).\n",
    "1. Se uma função é $ R \\to R ^ N $, o **modo de avanço** DA pode encontrar o jacobiano em $ O(1) $ sweeps.\n",
    "\n",
    "Vamos explorar dois tipos de diferenciação automática em Julia (e discutir alguns pacotes que os implementam). Para ambos, lembre-se da [regra da cadeia](https://en.wikipedia.org/wiki/Chain_rule):\n",
    "\n",
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{dw} \\cdot \\frac{dw}{dx}\n",
    "$$\n",
    "\n",
    "O modo de avanço inicia o cálculo da esquerda com $ \\frac{dy}{dw} $ primeiro, que calcula o produto com $ \\frac {dw} {dx} $. Por outro lado, o modo reverso inicia no lado direito com $ \\frac{dw}{dx} $ e trabalha para trás.\n",
    "\n",
    "Tomemos um exemplo de uma função com operações fundamentais e derivadas analíticas conhecidas:\n",
    "\n",
    "$$\n",
    "f(x_1, x_2) = x_1 x_2 + \\sin(x_1)\n",
    "$$\n",
    "\n",
    "E reescreva isso como uma função que contém uma sequência de operações simples e temporárias.\n",
    "\n",
    "Iremos explorar os pacotes Diferenciação Automática (*DA*) em Julia ao invés dos alternativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f(x_1, x_2)\n",
    "    w_1 = x_1\n",
    "    w_2 = x_2\n",
    "    w_3 = w_1 * w_2\n",
    "    w_4 = sin(w_1)\n",
    "    w_5 = w_3 + w_4\n",
    "    return w_5\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui podemos identificar todas as funções subjacentes (`*, sin, +`) e ver se cada uma possui uma\n",
    "derivada intrínseca. Embora isso seja óbvio, com Julia poderíamos criar todo tipo de regras de diferenciação para arbitrariamente\n",
    "combinações e composições complicadas de operações intrínsecas. De fato, há ainda [um pacote](https://github.com/JuliaDiff/ChainRules.jl) por registrar mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferenciação automática no modo de avanço\n",
    "\n",
    "Na *DA* de modo avançado, você primeiro corrige a variável na qual está interessado (chamado de \"propagação\") e depois avalia a regra da cadeia na ordem da esquerda para a direita.\n",
    "\n",
    "Por exemplo, com o exemplo de $ f(x_1, f_2) $ acima, se quisermos calcular a derivada em relação a $ x_1 $,\n",
    "podemos propagar a configuração de acordo.  $ \\frac{\\partial w_1}{\\partial x_1} = 1 $ desde que estamos usando a derivada, enquanto $ \\frac{\\partial w_1}{\\partial x_1} = 0 $.\n",
    "\n",
    "Depois disso, refaça todos os cálculos da derivada em paralelo com a própria função.\n",
    "$$\n",
    "\\begin{array}{l|l}\n",
    "f(x_1, x_2) &\n",
    "\\frac{\\partial f(x_1,x_2)}{\\partial x_1}\n",
    "\\\\\n",
    "\\hline\n",
    "w_1 = x_1 &\n",
    "\\frac{\\partial  w_1}{\\partial  x_1} = 1 \\text{ (seed)}\\\\\n",
    "w_2 = x_2 &\n",
    "\\frac{\\partial   w_2}{\\partial  x_1} = 0 \\text{ (seed)}\n",
    "\\\\\n",
    "w_3 = w_1 \\cdot w_2 &\n",
    "\\frac{\\partial  w_3}{\\partial x_1} = w_2 \\cdot \\frac{\\partial w_1}{\\partial x_1} + w_1 \\cdot \\frac{\\partial   w_2}{\\partial  x_1}\n",
    "\\\\\n",
    "w_4 = \\sin w_1 &\n",
    "\\frac{\\partial   w_4}{\\partial x_1} = \\cos w_1 \\cdot \\frac{\\partial  w_1}{\\partial x_1}\n",
    "\\\\\n",
    "w_5 = w_3 + w_4 &\n",
    "\\frac{\\partial  w_5}{\\partial x_1} = \\frac{\\partial  w_3}{\\partial x_1} + \\frac{\\partial  w_4}{\\partial x_1}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Como essas duas podem ser feitas ao mesmo tempo, dizemos que há \"uma passagem\" necessária para esse cálculo.\n",
    "\n",
    "Generalizando um pouco, se a função tivesse valor vetorial, esse passe único obteria toda a linha do jacobiano nesse passe único. Portanto, para uma função $ R^N \\to R^M $, são necessários passes de $ N $ para obter um jacobiano denso usando a DA de modo avançado.\n",
    "\n",
    "Como você pode implementar a DA de modo avançado? É bastante fácil, com uma linguagem de programação genérica, dar um exemplo simples (enquanto o \"diabo\" está nos detalhes de\n",
    "uma implementação de alto desempenho)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo de avanço com números duplos\n",
    "\n",
    "Uma maneira para implementar isso (usado no DA de modo avançado) é usar [números duplos](https://en.wikipedia.org/wiki/Dual_number).\n",
    "\n",
    "Em vez de trabalhar com apenas um número real, por exemplo. $ x $, aumentaremos cada um com um infinitesimal $ \\epsilon $ e usamos $ x + \\epsilon $.\n",
    "\n",
    "A partir do teorema de Taylor:\n",
    "\n",
    "$$\n",
    "f(x + \\epsilon) = f(x) + f'(x)\\epsilon + O(\\epsilon^2)\n",
    "$$\n",
    "\n",
    "onde vamos definir o infinitesimal tal que $ \\epsilon^2 = 0 $.\n",
    "\n",
    "Com essa definição, podemos escrever uma regra geral para diferenciação de $ g (x, y) $ como a regra de cadeia para a derivada total:\n",
    "\n",
    "$$\n",
    "g(x + \\epsilon, y + \\epsilon) = g(x, y) + (\\partial_x g(x,y) + \\partial_y g(x,y))\\epsilon\n",
    "$$\n",
    "\n",
    "Porém, observe que, se acompanharmos a constante na frente dos termos $ \\epsilon $ (por exemplo, um $ x' $ e $ y' $).\n",
    "\n",
    "$$\n",
    "g(x + x'\\epsilon, y + y'\\epsilon) = g(x, y) + (\\partial_x g(x,y)x' + \\partial_y g(x,y)y')\\epsilon\n",
    "$$\n",
    "\n",
    "Isso é simplesmente a regra da cadeia.  Um pouco mais de exemplos:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "        (x + x'\\epsilon) + (y + y'\\epsilon) &= (x + y) + (x' + y')\\epsilon\\\\\n",
    "(x + x'\\epsilon)\\times(y + y'\\epsilon) &= (xy) + (x'y + y'x)\\epsilon\\\\\n",
    "\\exp(x + x'\\epsilon) &= \\exp(x) + (x'\\exp(x))\\epsilon\\\\\n",
    "        \\end{aligned}\n",
    "$$\n",
    "\n",
    "Usando a programação genérica em Julia, é fácil definir um novo tipo de número duplo que pode encapsular o par $ (x, x') $ e fornecer definições para todas as operações básicas. Cada definição possui a regra da cadeia incorporada.\n",
    "\n",
    "Com essa abordagem, o processo “semente” é simples, a criação do $ \\epsilon $ para a variável subjacente.\n",
    "\n",
    "Portanto, se tivermos a função $ f(x_1, x_2) $ e desejarmos encontrar a derivada $ \\partial_{x_1} f(3.8, 6.9) $ então os semearíamos com os números duplos $ x_1 \\to (3.8, 1) $ e $ x_2 \\to (6.9, 0) $.\n",
    "\n",
    "Se você seguir todas as mesmas operações escalares acima com um número duplo inicial, ele calculará o valor da função e a derivada em uma única “varredura” e sem modificar nenhum código (genérico)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ForwardDiff.jl\n",
    "\n",
    "Os números duplos estão no coração de um dos pacotes da DA que já vimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ForwardDiff.gradient(h, x) = [26.354764961030977 16.663053156992284]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 1.818314452615056 \n",
       " 2.212251895373916 \n",
       " 2.461284516606687 \n",
       " 1.9514591707639093\n",
       " 1.8393629512203116"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "h(x) = sin(x[1]) + x[1] * x[2] + sinh(x[1] * x[2]) # multivariada.\n",
    "x = [1.4 2.2]\n",
    "@show ForwardDiff.gradient(h,x) # use DA, seeds de x\n",
    "\n",
    "#Ou, pode usar funções complicadas de muitas variáveis\n",
    "f(x) = sum(sin, x) + prod(tan, x) * sum(sqrt, x)\n",
    "g = (x) -> ForwardDiff.gradient(f, x); # g() é agora o gradiente\n",
    "g(rand(5)) # gradiente em um ponto aleatório\n",
    "# ForwardDiff.hessian(f,x') # ou o hessiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos até diferenciar automaticamente funções complicadas com iterações incorporadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function squareroot(x) #fingindo que não sabemos sqrt()\n",
    "    z = copy(x)  #Ponto inicial do método de Newton\n",
    "    while abs(z*z - x) > 1e-13\n",
    "        z = z - (z*z-x)/(2z)\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "squareroot(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35355339059327373"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "dsqrt(x) = ForwardDiff.derivative(squareroot, x)\n",
    "dsqrt(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zygote.jl\n",
    "\n",
    "Diferentemente da diferenciação automática no modo avançado, o modo reverso é muito difícil de implementar com eficiência, e há muitas variações na melhor abordagem.\n",
    "\n",
    "Muitos pacotes de modo reverso estão conectados a pacotes de aprendizado de máquina, pois os gradientes eficientes das funções de perda de $ R^N \\to R $ são necessários para os algoritmos de otimização de descida de gradiente usados no aprendizado de máquina.\n",
    "\n",
    "Um pacote recente é [Zygote.jl](https://github.com/FluxML/Zygote.jl), que é usado na estrutura Flux.jl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.0, 2.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Zygote\n",
    "\n",
    "h(x, y) = 3x^2 + 2x + 1 + y*x - y\n",
    "gradient(h, 3.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vemos que o Zygote tem uma função de gradiente como interface, que retorna uma tupla.\n",
    "\n",
    "Você pode criar isso como um operador se quiser.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6536436208636119"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(f) = x-> gradient(f, x)[1]  # Retorna a primera na tupla\n",
    "\n",
    "D_sin = D(sin)\n",
    "D_sin(4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para funções de uma variável (Julia), podemos encontrá-lo simplesmente usando o `'` após o nome de uma função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       "  0.3333333333333333\n",
       "  0.3333333333333333\n",
       " -0.3333333333333333"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "p(x) = mean(abs, x)\n",
    "p'([1.0, 3.0, -2.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, usando a função iterativa complicada que definimos para o quadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3535533905932737"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squareroot'(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Zygote suporta combinações de vetores e escalares como parâmetros de função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.13736056394868904, 0.5494422557947561, 0.8241633836921343], -1.2725553130925444)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x,n) = (sum(x.^n))^(1/n)\n",
    "gradient(h, [1.0, 4.0, 6.0], 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os gradientes podem ter dimensões muito altas. Por exemplo, para resolver um problema simples de otimização não linear\n",
    "com 1 milhão de dimensões, resolvidas em alguns segundos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum = 5.773501129493461 with in 2 iterations\n"
     ]
    }
   ],
   "source": [
    "using Optim, LinearAlgebra\n",
    "N = 1000000\n",
    "y = rand(N)\n",
    "λ = 0.01\n",
    "obj(x) = sum((x .- y).^2) + λ*norm(x)\n",
    "\n",
    "x_iv = rand(N)\n",
    "function g!(G, x)\n",
    "    G .=  obj'(x)\n",
    "end\n",
    "\n",
    "results = optimize(obj, g!, x_iv, LBFGS()) # ou ConjugateGradient()\n",
    "println(\"minimum = $(results.minimum) with in \"*\n",
    "\"$(results.iterations) iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuidado: embora o Zygote seja a implementação mais interessante da DA de modo reverso em Julia, ele possui muitas arestas.\n",
    "\n",
    "- Se você escreve uma função, pega seu gradiente e modifica a função, é necessário chamar `Zygote.refresh ()` ou o gradiente ficará fora de sincronia. Isso pode não se aplicar ao Julia 1.3 ou superior.\n",
    "- Ele não fornece recursos para obter jacobianos, portanto, você deve solicitar cada linha do jacobiano separadamente. Dito isto, você\n",
    "  provavelmente deseja usar o `ForwardDiff.jl` para jacobianos se a dimensão da saída for semelhante à dimensão da entrada.\n",
    "- Você não pode, no release atual, usar funções de mutação (por exemplo, modificar um valor em uma matriz, etc.), Embora esse recurso esteja em andamento.\n",
    "- A compilação pode ser muito lenta para funções complicadas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização\n",
    "\n",
    "Há um grande número de pacotes destinados a serem usadospara otimização na Julia.\n",
    "\n",
    "Parte do motivo da diversidade de opções é que Julia possibilita a implementação eficiente de um grande número de variações nas rotinas de otimização.\n",
    "\n",
    "A outra razão é que tipos diferentes de problemas de otimização requerem algoritmos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optim.jl\n",
    "\n",
    "Uma boa solução de Julia pura para a otimização (sem restrições ou limitada) da função univariada e multivariada é o pacote [Optim.jl](https://github.com/JuliaNLSolvers/Optim.jl).\n",
    "\n",
    "Por padrão, os algoritmos no `Optim.jl` levam a minimização do destino em vez de maximização, portanto, se uma função é chamada, `optimize` isso significa minimização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funções Univariadas em Intervalos limitados\n",
    "\n",
    "O padrão de [Otimização Univariada](http://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/#minimizing-a-univariate-function-on-a-bounded-interval)\n",
    "é uma rotina robusta de otimização híbrida chamada [método de Brent.](https://en.wikipedia.org/wiki/Brent%27s_method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Brent's Method\n",
       " * Search Interval: [-2.000000, 1.000000]\n",
       " * Minimizer: 0.000000e+00\n",
       " * Minimum: 0.000000e+00\n",
       " * Iterations: 5\n",
       " * Convergence: max(|x - x_upper|, |x - x_lower|) <= 2*(1.5e-08*|x|+2.2e-16): true\n",
       " * Objective Function Calls: 6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Optim\n",
    "using Optim: converged, maximum, maximizer, minimizer, iterations #algumas funções extras\n",
    "\n",
    "result = optimize(x-> x^2, -2.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sempre verifique se os resultados convergiram, e gere os erros caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converged(result) || error(\"Failed to converge in $(iterations(result)) iterations\")\n",
    "xmin = result.minimizer\n",
    "result.minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira linha é um OR lógico entre `converged(result)` e `error(\"...\")`.\n",
    "\n",
    "Se a verificação de convergência for aprovada, a sentença lógica será verdadeira e prosseguirá para a próxima linha; caso contrário, lançará o erro.\n",
    "\n",
    "Ou para maximizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = -x^2\n",
    "result = maximize(f, -2.0, 1.0)\n",
    "converged(result) || error(\"Failed to converge in $(iterations(result)) iterations\")\n",
    "xmin = maximizer(result)\n",
    "fmax = maximum(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Perceba que chamamos resultados `optimize` usando `result.minimizer`, e resultados para `maximize` usando `maximizer(result)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Otimização Multivariada Irrestrita\n",
    "\n",
    "Há uma variedade de [algorítimos e opções](http://julianlsolvers.github.io/Optim.jl/stable/#user/minimization/#_top) para otimização multivaridada.\n",
    "\n",
    "A partir da documentação, a versão mais simples é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: success\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [1.00e+00, 1.00e+00]\n",
       "    Minimum:   3.525527e-09\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Nelder-Mead\n",
       "    Initial Point: [0.00e+00, 0.00e+00]\n",
       "\n",
       " * Convergence measures\n",
       "    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    60\n",
       "    f(x) calls:    118\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "x_iv = [0.0, 0.0]\n",
    "results = optimize(f, x_iv) # por exemplo. optimize(f, x_iv, NelderMead())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algorítimo padrão em `NelderMead`, que é livre de derivadas e, portanto, requer muitas avaliações de função.\n",
    "\n",
    "Para mudar o tipo do algorítimo para [L-BFGS](http://julianlsolvers.github.io/Optim.jl/stable/#algo/lbfgs/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum = 5.3784046148998115e-17 with argmin = [0.9999999926662393, 0.9999999853324786] in 24 iterations\n"
     ]
    }
   ],
   "source": [
    "results = optimize(f, x_iv, LBFGS())\n",
    "println(\"minimum = $(results.minimum) with argmin = $(results.minimizer) in \"*\n",
    "\"$(results.iterations) iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que isso possui menos iterações.\n",
    "\n",
    "Como nenhuma derivada foi fornecida, utilizou [diferenças finitas](https://en.wikipedia.org/wiki/Finite_difference) para aproximar o gradiente de `f(x)`.\n",
    "\n",
    "No entanto,  como a maioria dos algoritmos exige derivadas, você frequentemente desejará usar a diferenciação automática ou passar gradientes analíticos, se possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum = 5.191703158437428e-27 with argmin = [0.999999999999928, 0.9999999999998559] in 24 iterations\n"
     ]
    }
   ],
   "source": [
    "f(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "x_iv = [0.0, 0.0]\n",
    "results = optimize(f, x_iv, LBFGS(), autodiff=:forward) # por exemplo use ForwardDiff.jl\n",
    "println(\"minimum = $(results.minimum) with argmin = $(results.minimizer) in \"*\n",
    "\"$(results.iterations) iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que não precisamos usar diretamente o `ForwardDiff.jl`, desde que nossa função `f(x)` foi escrita para ser genérica (veja a [aula de programação genérica](https://lectures.quantecon.org/generic_programming.html)).\n",
    "\n",
    "Alternativamente, com um gradiente analítico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum = 5.191703158437428e-27 with argmin = [0.999999999999928, 0.9999999999998559] in 24 iterations\n"
     ]
    }
   ],
   "source": [
    "f(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "x_iv = [0.0, 0.0]\n",
    "function g!(G, x)\n",
    "    G[1] = -2.0 * (1.0 - x[1]) - 400.0 * (x[2] - x[1]^2) * x[1]\n",
    "    G[2] = 200.0 * (x[2] - x[1]^2)\n",
    "end\n",
    "\n",
    "results = optimize(f, g!, x_iv, LBFGS()) # ou ConjugateGradient()\n",
    "println(\"minimum = $(results.minimum) with argmin = $(results.minimizer) in \"*\n",
    "\"$(results.iterations) iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para métodos sem derivadas, você pode alterar o algoritmo - e não precisa fornecer um gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " * Status: failure (reached maximum number of iterations) (line search failed)\n",
       "\n",
       " * Candidate solution\n",
       "    Minimizer: [7.79e-01, 6.00e-01]\n",
       "    Minimum:   5.355153e-02\n",
       "\n",
       " * Found with\n",
       "    Algorithm:     Simulated Annealing\n",
       "    Initial Point: [0.00e+00, 0.00e+00]\n",
       "\n",
       " * Convergence measures\n",
       "    |x - x'|               = NaN ≰ 0.0e+00\n",
       "    |x - x'|/|x'|          = NaN ≰ 0.0e+00\n",
       "    |f(x) - f(x')|         = NaN ≰ 0.0e+00\n",
       "    |f(x) - f(x')|/|f(x')| = NaN ≰ 0.0e+00\n",
       "    |g(x)|                 = NaN ≰ 1.0e-08\n",
       "\n",
       " * Work counters\n",
       "    Seconds run:   0  (vs limit Inf)\n",
       "    Iterations:    1000\n",
       "    f(x) calls:    1001\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "x_iv = [0.0, 0.0]\n",
    "results = optimize(f, x_iv, SimulatedAnnealing()) # ou ParticleSwarm() ou NelderMead()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, você observará que isso não convergiu, pois os métodos estocásticos geralmente exigem muito mais iterações como uma troca por suas propriedades de convergência global.\n",
    "\n",
    "Veja o exemplo de [probabilidade máxima](http://julianlsolvers.github.io/Optim.jl/stable/#examples/generated/maxlikenlm/)\n",
    "e [notebook Jupyter](https://nbviewer.jupyter.org/github/JuliaNLSolvers/Optim.jl/blob/gh-pages/v0.15.3/examples/generated/maxlikenlm.ipynb) que o acompanha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JuMP.jl\n",
    "\n",
    "O pacote  [JuMP.jl](https://github.com/JuliaOpt/JuMP.jl) é uma ambiciosa implementação de uma linguagem de modelagem para problemas de otimização em Julia.\n",
    "\n",
    "Nesse sentido, é mais parecido com um AMPL (ou Pyomo) construído sobre a linguagem Julia com macros e capaz de usar uma variedade de diferentes solucionadores comerciais e de código aberto.\n",
    "\n",
    "Se você tiver um problema linear, quadrático, cônico, linear inteiro misto, etc. esse provavelmente será o “mega-pacote” ideal para chamar vários solucionadores.\n",
    "\n",
    "Para problemas não-lineares, a linguagem de modelagem pode dificultar as funções complicadas (pois não foi projetada para ser usada como um otimizador não-linear de uso geral).\n",
    "\n",
    "Veja o [guia de inicio rápido](http://www.juliaopt.org/JuMP.jl/0.18/quickstart.html) para mais detalhes em todas as opções.\n",
    "\n",
    "A seguir, é apresentado um exemplo de como chamar um objetivo linear com uma restrição não linear (fornecida por uma função externa).\n",
    "\n",
    "Aqui `Ipopt` apoia `Interior Point OPTimizer`, [solucinador](https://github.com/JuliaOpt/Ipopt.jl) em Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit http://projects.coin-or.org/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        2\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        1\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        1\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0 -1.0000000e+00 0.00e+00 2.07e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1 -1.4100714e+00 0.00e+00 5.48e-02  -1.7 3.94e-01    -  1.00e+00 7.36e-01f  1\n",
      "   2 -1.4113851e+00 0.00e+00 2.83e-08  -2.5 9.29e-04    -  1.00e+00 1.00e+00f  1\n",
      "   3 -1.4140632e+00 0.00e+00 1.50e-09  -3.8 1.89e-03    -  1.00e+00 1.00e+00f  1\n",
      "   4 -1.4142117e+00 0.00e+00 1.84e-11  -5.7 1.05e-04    -  1.00e+00 1.00e+00f  1\n",
      "   5 -1.4142136e+00 0.00e+00 8.23e-09  -8.6 1.30e-06    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 5\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:  -1.4142135740093271e+00   -1.4142135740093271e+00\n",
      "Dual infeasibility......:   8.2280586788385790e-09    8.2280586788385790e-09\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.5059035815063646e-09    2.5059035815063646e-09\n",
      "Overall NLP error.......:   8.2280586788385790e-09    8.2280586788385790e-09\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 6\n",
      "Number of objective gradient evaluations             = 6\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 6\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 6\n",
      "Number of Lagrangian Hessian evaluations             = 5\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      1.698\n",
      "Total CPU secs in NLP function evaluations           =      1.418\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "JuMP.optimize!(m) = nothing\n"
     ]
    }
   ],
   "source": [
    "using JuMP, Ipopt\n",
    "# Resolva\n",
    "# max( x[1] + x[2] )\n",
    "# st sqrt(x[1]^2 + x[2]^2) <= 1\n",
    "\n",
    "function squareroot(x) #fingindo que não sabemos sqrt()\n",
    "    z = x #  Ponto de início inicial do método de Newton\n",
    "    while abs(z*z - x) > 1e-13\n",
    "        z = z - (z*z-x)/(2z)\n",
    "    end\n",
    "    return z\n",
    "end\n",
    "m = Model(with_optimizer(Ipopt.Optimizer))\n",
    "# precisa registrar funções definidas pelo usuário para o DA\n",
    "JuMP.register(m,:squareroot, 1, squareroot, autodiff=true)\n",
    "\n",
    "@variable(m, x[1:2], start=0.5) # start é a condição inicial \n",
    "@objective(m, Max, sum(x))\n",
    "@NLconstraint(m, squareroot(x[1]^2+x[2]^2) <= 1)\n",
    "@show JuMP.optimize!(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E este é um exemplo de objetivo quadrático."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.0000000e+00 0.00e+00 2.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  9.5312500e-01 0.00e+00 1.25e+01  -1.0 1.00e+00    -  1.00e+00 2.50e-01f  3\n",
      "   2  4.8320569e-01 0.00e+00 1.01e+00  -1.0 9.03e-02    -  1.00e+00 1.00e+00f  1\n",
      "   3  4.5708829e-01 0.00e+00 9.53e+00  -1.0 4.29e-01    -  1.00e+00 5.00e-01f  2\n",
      "   4  1.8894205e-01 0.00e+00 4.15e-01  -1.0 9.51e-02    -  1.00e+00 1.00e+00f  1\n",
      "   5  1.3918726e-01 0.00e+00 6.51e+00  -1.7 3.49e-01    -  1.00e+00 5.00e-01f  2\n",
      "   6  5.4940990e-02 0.00e+00 4.51e-01  -1.7 9.29e-02    -  1.00e+00 1.00e+00f  1\n",
      "   7  2.9144630e-02 0.00e+00 2.27e+00  -1.7 2.49e-01    -  1.00e+00 5.00e-01f  2\n",
      "   8  9.8586451e-03 0.00e+00 1.15e+00  -1.7 1.10e-01    -  1.00e+00 1.00e+00f  1\n",
      "   9  2.3237475e-03 0.00e+00 1.00e+00  -1.7 1.00e-01    -  1.00e+00 1.00e+00f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  2.3797236e-04 0.00e+00 2.19e-01  -1.7 5.09e-02    -  1.00e+00 1.00e+00f  1\n",
      "  11  4.9267371e-06 0.00e+00 5.95e-02  -1.7 2.53e-02    -  1.00e+00 1.00e+00f  1\n",
      "  12  2.8189505e-09 0.00e+00 8.31e-04  -2.5 3.20e-03    -  1.00e+00 1.00e+00f  1\n",
      "  13  1.0095040e-15 0.00e+00 8.68e-07  -5.7 9.78e-05    -  1.00e+00 1.00e+00f  1\n",
      "  14  1.3288608e-28 0.00e+00 2.02e-13  -8.6 4.65e-08    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 14\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   1.3288608467480825e-28    1.3288608467480825e-28\n",
      "Dual infeasibility......:   2.0183854587685121e-13    2.0183854587685121e-13\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   2.0183854587685121e-13    2.0183854587685121e-13\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 36\n",
      "Number of objective gradient evaluations             = 15\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 14\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.077\n",
      "Total CPU secs in NLP function evaluations           =      0.010\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "x = 0.9999999999999899 y = 0.9999999999999792\n",
      "This is Ipopt version 3.12.10, running with linear solver mumps.\n",
      "NOTE: Other linear solvers might be more efficient (see Ipopt documentation).\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        2\n",
      "Number of nonzeros in inequality constraint Jacobian.:        0\n",
      "Number of nonzeros in Lagrangian Hessian.............:        3\n",
      "\n",
      "Total number of variables............................:        2\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        1\n",
      "Total number of inequality constraints...............:        0\n",
      "        inequality constraints with only lower bounds:        0\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:        0\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.0000000e+00 1.00e+01 1.00e+00  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  9.6315968e+05 0.00e+00 3.89e+05  -1.0 9.91e+00    -  1.00e+00 1.00e+00h  1\n",
      "   2  1.6901461e+05 0.00e+00 1.16e+05  -1.0 3.24e+00    -  1.00e+00 1.00e+00f  1\n",
      "   3  2.5433173e+04 1.78e-15 3.18e+04  -1.0 2.05e+00    -  1.00e+00 1.00e+00f  1\n",
      "   4  2.6527756e+03 0.00e+00 7.79e+03  -1.0 1.19e+00    -  1.00e+00 1.00e+00f  1\n",
      "   5  1.1380324e+02 0.00e+00 1.35e+03  -1.0 5.62e-01    -  1.00e+00 1.00e+00f  1\n",
      "   6  3.3745506e+00 0.00e+00 8.45e+01  -1.0 1.50e-01    -  1.00e+00 1.00e+00f  1\n",
      "   7  2.8946196e+00 0.00e+00 4.22e-01  -1.0 1.07e-02    -  1.00e+00 1.00e+00f  1\n",
      "   8  2.8946076e+00 0.00e+00 1.07e-05  -1.7 5.42e-05    -  1.00e+00 1.00e+00f  1\n",
      "   9  2.8946076e+00 0.00e+00 5.91e-13  -8.6 1.38e-09    -  1.00e+00 1.00e+00f  1\n",
      "\n",
      "Number of Iterations....: 9\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   2.8946075504894599e+00    2.8946075504894599e+00\n",
      "Dual infeasibility......:   5.9130478291535837e-13    5.9130478291535837e-13\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Overall NLP error.......:   5.9130478291535837e-13    5.9130478291535837e-13\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 10\n",
      "Number of objective gradient evaluations             = 10\n",
      "Number of equality constraint evaluations            = 10\n",
      "Number of inequality constraint evaluations          = 0\n",
      "Number of equality constraint Jacobian evaluations   = 1\n",
      "Number of inequality constraint Jacobian evaluations = 0\n",
      "Number of Lagrangian Hessian evaluations             = 9\n",
      "Total CPU secs in IPOPT (w/o function evaluations)   =      0.002\n",
      "Total CPU secs in NLP function evaluations           =      0.000\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "x = 2.701147124098218 y = 7.2988528759017814\n"
     ]
    }
   ],
   "source": [
    "# resolva\n",
    "# min (1-x)^2 + 100(y-x^2)^2)\n",
    "# st x + y >= 10\n",
    "\n",
    "using JuMP,Ipopt\n",
    "m = Model(with_optimizer(Ipopt.Optimizer)) # configurações para a solução\n",
    "@variable(m, x, start = 0.0)\n",
    "@variable(m, y, start = 0.0)\n",
    "\n",
    "@NLobjective(m, Min, (1-x)^2 + 100(y-x^2)^2)\n",
    "\n",
    "JuMP.optimize!(m)\n",
    "println(\"x = \", value(x), \" y = \", value(y))\n",
    "\n",
    "# adicionando uma restrição (linear)\n",
    "@constraint(m, x + y == 10)\n",
    "JuMP.optimize!(m)\n",
    "println(\"x = \", value(x), \" y = \", value(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlackBoxOptim.jl\n",
    "\n",
    "Outro pacote para a otimização global sem derivadas é o [BlackBoxOptim.jl](https://github.com/robertfeldt/BlackBoxOptim.jl).\n",
    "\n",
    "Para ver um exemplo da documentação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting optimization with optimizer DiffEvoOpt{FitPopulation{Float64},RadiusLimitedSelector,BlackBoxOptim.AdaptiveDiffEvoRandBin{3},RandomBound{ContinuousRectSearchSpace}}\n",
      "0.00 secs, 0 evals, 0 steps\n",
      "\n",
      "Optimization stopped after 10001 steps and 0.09 seconds\n",
      "Termination reason: Max number of steps (10000) reached\n",
      "Steps per second = 112462.99\n",
      "Function evals per second = 114228.49\n",
      "Improvements/step = 0.21650\n",
      "Total function evaluations = 10158\n",
      "\n",
      "\n",
      "Best candidate found: [1.0, 1.0]\n",
      "\n",
      "Fitness: 0.000000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "using BlackBoxOptim\n",
    "\n",
    "function rosenbrock2d(x)\n",
    "return (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2\n",
    "end\n",
    "\n",
    "results = bboptimize(rosenbrock2d; SearchRange = (-5.0, 5.0), NumDimensions = 2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um exemplo para  [execução paralela](https://github.com/robertfeldt/BlackBoxOptim.jl/blob/master/examples/rosenbrock_parallel.jl) do objetivo é fornecido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sistema de Equações e Mínimos Quadrados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roots.jl\n",
    "\n",
    "A raiz de uma função real $ f $ em $ [a,b] $ é um $ x \\in [a, b] $ tal que $ f(x)=0 $\n",
    "\n",
    "Por exemplo, se plotarmos a função:\n",
    "\n",
    "\n",
    "<a id='equation-root-f'></a>\n",
    "$$\n",
    "f(x) = \\sin(4 (x - 1/4)) + x + x^{20} - 1 \\tag{1}\n",
    "$$\n",
    "\n",
    "com $ x \\in [0,1] $ nós obtemos:\n",
    "\n",
    "<img src=\"https://julia.quantecon.org/more_julia/_static/figures/sine-screenshot-2.png\" style=\"width:50%;\">\n",
    "\n",
    "  \n",
    "A única raiz aproximada é 0.408.\n",
    "\n",
    "O pacote [Roots.jl](https://github.com/JuliaLang/Roots.jl) oferece `fzero()` para encontrar as raizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40829350427936706"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Roots\n",
    "f(x) = sin(4 * (x - 1/4)) + x + x^20 - 1\n",
    "fzero(f, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLsolve.jl\n",
    "\n",
    "O pacote [NLsolve.jl](https://github.com/JuliaNLSolvers/NLsolve.jl/) fornece funções para resolver sistemas multivariados e equações e pontos fixos.\n",
    "\n",
    "A partir da documentação, resolver um sistema de equações sem fornecer um método jacobiano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Nonlinear Solver Algorithm\n",
       " * Algorithm: Trust-region with dogleg and autoscaling\n",
       " * Starting Point: [0.1, 1.2]\n",
       " * Zero: [-7.775508345910301e-17, 0.9999999999999999]\n",
       " * Inf-norm of residuals: 0.000000\n",
       " * Iterations: 4\n",
       " * Convergence: true\n",
       "   * |x - x'| < 0.0e+00: false\n",
       "   * |f(x)| < 1.0e-08: true\n",
       " * Function Calls (f): 5\n",
       " * Jacobian Calls (df/dx): 5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NLsolve\n",
    "\n",
    "f(x) = [(x[1]+3)*(x[2]^3-7)+18\n",
    "        sin(x[2]*exp(x[1])-1)] # retorna um array\n",
    "\n",
    "results = nlsolve(f, [ 0.1; 1.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso acima, o algoritmo usou diferenças finitas para calcular o jacobiano.\n",
    "\n",
    "Como alternativa, se `f(x)` for escrito genericamente, você poderá usar a diferenciação automática com uma única configuração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged=true at root=[-3.487552479724522e-16, 1.0000000000000002] in 4 iterations and 5 function calls\n"
     ]
    }
   ],
   "source": [
    "results = nlsolve(f, [ 0.1; 1.2], autodiff=:forward)\n",
    "\n",
    "println(\"converged=$(NLsolve.converged(results)) at root=$(results.zero) in \"*\n",
    "\"$(results.iterations) iterations and $(results.f_calls) function calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fornecer uma função que opera no local (isto é, modifica um argumento) pode ajudar o desempenho de grandes sistemas de equações (e prejudicá-lo para os pequenos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged=true at root=[-3.487552479724522e-16, 1.0000000000000002] in 4 iterations and 5 function calls\n"
     ]
    }
   ],
   "source": [
    "function f!(F, x) # modifica o primeiro argumento\n",
    "    F[1] = (x[1]+3)*(x[2]^3-7)+18\n",
    "    F[2] = sin(x[2]*exp(x[1])-1)\n",
    "end\n",
    "\n",
    "results = nlsolve(f!, [ 0.1; 1.2], autodiff=:forward)\n",
    "\n",
    "println(\"converged=$(NLsolve.converged(results)) at root=$(results.zero) in \"*\n",
    "\"$(results.iterations) iterations and $(results.f_calls) function calls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeastSquaresOptim.jl\n",
    "\n",
    "Muitos problemas de otimização podem ser resolvidos usando mínimos quadrados lineares ou não lineares.\n",
    "\n",
    "Seja $ x \\in R^N $ e $ F(x) : R^N \\to R^M $ com $ M \\geq N $, então o problema de mínimos quadrados não lineares é:\n",
    "\n",
    "$$\n",
    "\\min_x F(x)^T F(x)\n",
    "$$\n",
    "\n",
    "Enquanto $ F(x)^T F(x) \\to R $, e portanto esse problema pode tecnicamente usar qualquer otimizador não linear, é usual explorar a estrutura do problema.\n",
    "\n",
    "Em particular, o Jacobiano de $ F(x) $, pode ser usado para aproximar o Hessiano do objetivo.\n",
    "\n",
    "Como na maioria dos problemas de otimização não linear, os benefícios geralmente se tornam evidentes somente quando a diferenciação analítica ou automática é possível.\n",
    "\n",
    "Se $ M = N $ e conhecemos uma raiz $ F(x^*) = 0 $ o sistema de equações existe, então NLS (non linear least squares) \n",
    "é o método de fato para resolver grandes **sistemas de equações**.\n",
    "\n",
    "Uma implementação do NLS é fornecida em [LeastSquaresOptim.jl](https://github.com/matthieugomez/LeastSquaresOptim.jl).\n",
    "\n",
    "A partir da documentação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Dogleg\n",
       " * Minimizer: [1.0,1.0]\n",
       " * Sum of squares at Minimum: 0.000000\n",
       " * Iterations: 51\n",
       " * Convergence: true\n",
       " * |x - x'| < 1.0e-08: false\n",
       " * |f(x) - f(x')| / |f(x)| < 1.0e-08: true\n",
       " * |g(x)| < 1.0e-08: false\n",
       " * Function Calls: 52\n",
       " * Gradient Calls: 36\n",
       " * Multiplication Calls: 159\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LeastSquaresOptim\n",
    "function rosenbrock(x)\n",
    "    [1 - x[1], 100 * (x[2]-x[1]^2)]\n",
    "end\n",
    "LeastSquaresOptim.optimize(rosenbrock, zeros(2), Dogleg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** Como existe um conflito de nomes entre `Optim.jl` e esse pacote, para ambos precisamos qualificar o uso da função `optimize` (por exemplo, `LeastSquaresOptim.optimize`).\n",
    "\n",
    "Aqui, por padrão, ele usará a *DA* com `ForwardDiff.jl` para calcular o Jacobiano,\n",
    "mas você também poderá fornecer seu próprio cálculo do jacobiano (analítico ou usando diferenças finitas) e/ou calcular a função no local."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Results of Optimization Algorithm\n",
       " * Algorithm: Dogleg\n",
       " * Minimizer: [1.0,1.0]\n",
       " * Sum of squares at Minimum: 0.000000\n",
       " * Iterations: 51\n",
       " * Convergence: true\n",
       " * |x - x'| < 1.0e-08: false\n",
       " * |f(x) - f(x')| / |f(x)| < 1.0e-08: true\n",
       " * |g(x)| < 1.0e-08: false\n",
       " * Function Calls: 52\n",
       " * Gradient Calls: 36\n",
       " * Multiplication Calls: 159\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rosenbrock_f!(out, x)\n",
    "    out[1] = 1 - x[1]\n",
    "    out[2] = 100 * (x[2]-x[1]^2)\n",
    "end\n",
    "LeastSquaresOptim.optimize!(LeastSquaresProblem(x = zeros(2),\n",
    "                                f! = rosenbrock_f!, output_length = 2))\n",
    "\n",
    "# Se quiser use o gradiente\n",
    "function rosenbrock_g!(J, x)\n",
    "    J[1, 1] = -1\n",
    "    J[1, 2] = 0\n",
    "    J[2, 1] = -200 * x[1]\n",
    "    J[2, 2] = 100\n",
    "end\n",
    "LeastSquaresOptim.optimize!(LeastSquaresProblem(x = zeros(2),\n",
    "                                f! = rosenbrock_f!, g! = rosenbrock_g!, output_length = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas Adicionais\n",
    "\n",
    "Assista a [esse vídeo](https://www.youtube.com/watch?v=vAp6nUMrKYg&feature=youtu.be) de um dos criadores de Julia sobre diferenciação automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1\n",
    "\n",
    "A execução simples de diferenciação automática de modo avançado é muito fácil em Julia, pois é genérica. Neste exercício, você\n",
    "preencherá algumas das operações necessárias para uma implementação simples da DA.\n",
    "\n",
    "Primeiro, precisamos fornecer um tipo para armazenar o dual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "struct DualNumber{T} <: Real\n",
    "    val::T\n",
    "    ϵ::T\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui nós o tornamos um subtipo de `Real` para que ele possa passar por funções que esperam reais.\n",
    "\n",
    "Podemos adicionar uma variedade de definições de regra de cadeia importando nas funções apropriadas e adicionando versões DualNumber. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+ (generic function with 265 methods)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +, *, -, ^, exp\n",
    "+(x::DualNumber, y::DualNumber) = DualNumber(x.val + y.val, x.ϵ + y.ϵ)  #  adição dual\n",
    "+(x::DualNumber, a::Number) = DualNumber(x.val + a, x.ϵ)  # ou seja, adição escalar, não dual\n",
    "+(a::Number, x::DualNumber) = DualNumber(x.val + a, x.ϵ)  # ou seja, adição escalar, não dual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso, podemos semear um número duplo e encontrar derivadas simples,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hide-output": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualNumber{Float64}(8.0, 1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x, y) = 3.0 + x + y\n",
    "\n",
    "x = DualNumber(2.0, 1.0)  # x -> 2.0 + 1.0 \\epsilon\n",
    "y = DualNumber(3.0, 0.0)  # ou seja. y = 3.0, sem derivada\n",
    "\n",
    "\n",
    "# seeded calcula a função e o gradiente d / dx!\n",
    "f(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para essa tarefa:\n",
    "\n",
    "1. Adicione regras da DA para as outras operações: `*, -, ^, exp`.\n",
    "1. Crie alguns exemplos de funções univariadas e multivariadas que combinam essas operações e use sua implementação da DA para encontrar as derivadas."
   ]
  }
 ],
 "metadata": {
  "date": 1580349905.0281777,
  "download_nb": 1,
  "download_nb_path": "https://julia.quantecon.org/",
  "filename": "optimization_solver_packages.rst",
  "filename_with_path": "more_julia/optimization_solver_packages",
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  },
  "title": "Solvers, Optimizers, and Automatic Differentiation"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
